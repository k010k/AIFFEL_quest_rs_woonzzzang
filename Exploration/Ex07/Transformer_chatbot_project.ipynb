{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc52dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f9eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ad1a4",
   "metadata": {},
   "source": [
    "### 포지셔널 행렬 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ce25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bfba9",
   "metadata": {},
   "source": [
    "### Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb54f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ab7e0",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc283ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value) \n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa8f75",
   "metadata": {},
   "source": [
    "### Padding masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b197ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc42732",
   "metadata": {},
   "source": [
    "### Look ahead masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b013a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16142ea",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d112ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f97143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f73be4",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1878595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c959244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdced2",
   "metadata": {},
   "source": [
    "### 데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb209848",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/ChatbotData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1799479598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 데이터 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ChatbotData.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 각각 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ChatbotData.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"data/ChatbotData.csv\")\n",
    "\n",
    "# 각각 저장\n",
    "df[\"Q\"].to_csv(\"data/question.txt\", index=False, header=False)\n",
    "df[\"A\"].to_csv(\"data/answer.txt\", index=False, header=False)\n",
    "df[\"label\"].to_csv(\"data/label.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a889b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /aiffel/aiffel/transformer_chatbot\n",
      "data 폴더 존재 여부: True\n",
      "data 폴더 내부 파일 목록: ['ChatbotData .csv', 'answer.txt', 'label.txt', 'question.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 현재 디렉토리 출력\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# data 폴더가 존재하는지 확인\n",
    "print(\"data 폴더 존재 여부:\", os.path.exists(\"data\"))\n",
    "\n",
    "# data 폴더 안의 파일 목록 출력\n",
    "if os.path.exists(\"data\"):\n",
    "    print(\"data 폴더 내부 파일 목록:\", os.listdir(\"data\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12ed2a",
   "metadata": {},
   "source": [
    "오류가 나서 보니 ChatbotData 파일명에 공백이 포함되어 있었다 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7796094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"data/ChatbotData .csv\")\n",
    "\n",
    "# 각각 저장\n",
    "df[\"Q\"].to_csv(\"data/question.txt\", index=False, header=False)\n",
    "df[\"A\"].to_csv(\"data/answer.txt\", index=False, header=False)\n",
    "df[\"label\"].to_csv(\"data/label.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0438267",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath(\"data\")\n",
    "\n",
    "# 저장된 파일 경로 출력\n",
    "question_path = os.path.join(base_path, \"question.txt\")\n",
    "answer_path = os.path.join(base_path, \"answer.txt\")\n",
    "label_path = os.path.join(base_path, \"label.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c803ef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac76c42",
   "metadata": {},
   "source": [
    "데이터가 그리 크지는 않아서 따로 샘플 최대 개수를 설정하지는 않겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297cca9",
   "metadata": {},
   "source": [
    "### 전처리 함수\n",
    "한글 데이터이므로 기존 전처리 함수에서\n",
    "- 소문자 변경 삭제\n",
    "- 한글 정규식 범위 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ca3dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 구두점(?.!,) 앞뒤에 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "    # 연속된 공백을 하나의 공백으로 변환\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "\n",
    "    # 한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "\n",
    "    # 최종 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a99057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수: 11823\n",
      "전체 샘플 수: 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리 함수\n",
    "\n",
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "\n",
    "def load_conversations():\n",
    "    # CSV 데이터 로드\n",
    "    df = pd.read_csv(\"data/ChatbotData .csv\")\n",
    "\n",
    "    # Q: 질문, A: 답변을 리스트로 저장\n",
    "    inputs = df[\"Q\"].tolist()\n",
    "    outputs = df[\"A\"].tolist()\n",
    "\n",
    "    # 전처리 적용\n",
    "    inputs = [preprocess_sentence(q) for q in inputs]\n",
    "    outputs = [preprocess_sentence(a) for a in outputs]\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "# 함수 실행\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수:', len(questions))\n",
    "print('전체 샘플 수:', len(answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe1adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0fd2d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ce7d3",
   "metadata": {},
   "source": [
    "## 병렬 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ed294",
   "metadata": {},
   "source": [
    "### 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e47e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d50e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df626bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8164]\n",
      "END_TOKEN의 번호 : [8165]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef1dcdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8166\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475587c7",
   "metadata": {},
   "source": [
    "### 각 단어를 고유한 정수로 인코딩 & 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8f8083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5759, 610, 2488, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7504, 7, 6269, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70d90604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문(Q) 최대 길이 (문자 수 기준): 57\n",
      "답변(A) 최대 길이 (문자 수 기준): 78\n"
     ]
    }
   ],
   "source": [
    "# 문장 길이 계산 (문자 개수 기준)\n",
    "max_q_length = max(len(q) for q in questions)\n",
    "max_a_length = max(len(a) for a in answers)\n",
    "\n",
    "print(f\"질문(Q) 최대 길이 (문자 수 기준): {max_q_length}\")\n",
    "print(f\"답변(A) 최대 길이 (문자 수 기준): {max_a_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b96233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880f14f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79f2a170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8166\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b58e6",
   "metadata": {},
   "source": [
    "### 교사 강요 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf4e9eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444c809",
   "metadata": {},
   "source": [
    "## 모델 정의 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d61a7",
   "metadata": {},
   "source": [
    "### 트랜스포머 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d785da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fffb74",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7be4352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 768)    31496704    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 768)    50407936    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8166)   6279654     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 88,184,294\n",
      "Trainable params: 88,184,294\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 8 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 768 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 12 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.3 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ea7db",
   "metadata": {},
   "source": [
    "### 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5620c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8f3fb",
   "metadata": {},
   "source": [
    "### 커스텀 된 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e740f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=8000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c286a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=768)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106edfb",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5982cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e886088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 108s 460ms/step - loss: 1.3776 - accuracy: 0.0204\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 1.1896 - accuracy: 0.0252\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 1.0784 - accuracy: 0.0425\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 85s 460ms/step - loss: 1.0218 - accuracy: 0.0497\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.9913 - accuracy: 0.0501\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.9644 - accuracy: 0.0507\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.9453 - accuracy: 0.0513\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.9296 - accuracy: 0.0520\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.9156 - accuracy: 0.0526\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 85s 460ms/step - loss: 0.9033 - accuracy: 0.0530\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.8922 - accuracy: 0.0535\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.8808 - accuracy: 0.0540\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.8690 - accuracy: 0.0544\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.8571 - accuracy: 0.0549\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.8464 - accuracy: 0.0552\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.8355 - accuracy: 0.0554\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.8243 - accuracy: 0.0560\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.8136 - accuracy: 0.0564\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.8029 - accuracy: 0.0570\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.7944 - accuracy: 0.0573\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.7845 - accuracy: 0.0577\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.7749 - accuracy: 0.0578\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7665 - accuracy: 0.0582\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 85s 458ms/step - loss: 0.7576 - accuracy: 0.0586\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7482 - accuracy: 0.0588\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7396 - accuracy: 0.0591\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7308 - accuracy: 0.0594\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7237 - accuracy: 0.0596\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7147 - accuracy: 0.0601\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 85s 459ms/step - loss: 0.7089 - accuracy: 0.0601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5279f3f8e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440d994",
   "metadata": {},
   "source": [
    "## 챗봇 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e28e4",
   "metadata": {},
   "source": [
    "### decoder_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40374fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "023a6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2953ad",
   "metadata": {},
   "source": [
    "### 임의 문장 test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72643ffb",
   "metadata": {},
   "source": [
    "기본 코드로 학습시킨 결과  \n",
    "첫 질문은 반대의 대답을 하고 두 번째 질문은 말이 되는 듯 하다  \n",
    "\n",
    "[전처리]    \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수    \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.1 # 드롭아웃의 비율   \n",
    "EPOCHS = 10   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e93219f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 직접 물어보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요 .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5803ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 헤어졌어.\n",
      "출력 : 잘 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 될 거예요 .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e5507",
   "metadata": {},
   "source": [
    "### 임의 문장 test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5875d65",
   "metadata": {},
   "source": [
    "교사 강요에서 BUFFER_SIZE 만 5000으로 수정한 결과  \n",
    "전 보다는 어느 정도 말이 되긴 하지만 그래도 아직 부족하다  \n",
    "acc도 0.06 대  \n",
    "  \n",
    "[전처리]    \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수    \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.1 # 드롭아웃의 비율   \n",
    "EPOCHS = 10   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "842f2614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 좋아하는 마음을 대화를 해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋아하는 마음을 대화를 해보세요 .'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "818eaea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 헤어졌어.\n",
      "출력 : 좋은 사람 만날 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 사람 만날 수 있을 거예요 .'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e678236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 혼자 노력하는 연애인 거 같아.\n",
      "출력 : 마음이 복잡하겠어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음이 복잡하겠어요 .'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('혼자 노력하는 연애인 거 같아.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd905c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 크리스마스인데 만나자고 해도 됨?\n",
      "출력 : 좋아하는 마음을 대화를 해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋아하는 마음을 대화를 해보세요 .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('크리스마스인데 만나자고 해도 됨?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f95a08aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 좋은 사람 만날 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 사람 만날 수 있을 거예요 .'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1497f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 심심해.\n",
      "출력 : 좋은 사람 만날 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 사람 만날 수 있을 거예요 .'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 심심해.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7539256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 저녁 뭐 먹을까?\n",
      "출력 : 좋은 곳으로 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 곳으로 될 거예요 .'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 저녁 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4efc342",
   "metadata": {},
   "source": [
    "### 임의 문장 test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52f4dd",
   "metadata": {},
   "source": [
    "lr의 d_model 과 동일하게 128로 맞춤  \n",
    "드롭아웃도 0.5로 키우고  \n",
    "교사 강요 batch_size도 16으로 줄였다  \n",
    "결과는 ..... 처참합니다    \n",
    "그리고 BUFFER SIZE 관련해서 영진님께서 캐시에 있는 데이터를 버퍼에서 셔플하여 데이터의 편향을 막으려고 사용한 것이므로    \n",
    "5000개만 데이터를 섞게 되면 편향이 생길 수 있다는 의견을 공유해주셨다    \n",
    "확실히 결과를 보면 그런 것 같다  \n",
    "따라서 다음 test에는 다시 20000으로 복귀..   \n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.5 # 드롭아웃의 비율   \n",
    "EPOCHS = 10   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 16   \n",
    "BUFFER_SIZE = 5000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07182af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 좋은 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 '"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00fd986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 좋은 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33b6ab",
   "metadata": {},
   "source": [
    "### 임의 문장 test 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d93d83",
   "metadata": {},
   "source": [
    "교사 강요 파라미터를 다시 원복하고 에폭만 20으로 늘려봤다  \n",
    "Epoch 20/20\n",
    "185/185 [==============================] - 15s 82ms/step - loss: 0.7520 - accuracy: 0.0595   \n",
    "잘 되길 바랄게요 앵무새가 됐다  \n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.5 # 드롭아웃의 비율   \n",
    "EPOCHS = 20   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d25cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 그런 사람 만나길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그런 사람 만나길 바랄게요 .'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0a44ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 헤어졌어.\n",
      "출력 : 잘 되길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 되길 바랄게요 .'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13a71d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 크리스마스인데 만나자고 해도 됨?\n",
      "출력 : 사람마다 사람 솔직하 수도 있어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사람마다 사람 솔직하 수도 있어요 .'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('크리스마스인데 만나자고 해도 됨?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc463367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 잘 되길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 되길 바랄게요 .'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3066aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 심심해.\n",
      "출력 : 잘 되길 바랄게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 되길 바랄게요 .'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 심심해.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efed43",
   "metadata": {},
   "source": [
    "### 임의 문장 test 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cff392",
   "metadata": {},
   "source": [
    "d_model을 lr, model 모두 256으로 맞춤   \n",
    "드롭아웃 0.3   \n",
    "Epoch 20/20\n",
    "185/185 [==============================] - 22s 118ms/step - loss: 0.6597 - accuracy: 0.0658   \n",
    "표현이 좀 더 다양해진 것 같다\n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.3 # 드롭아웃의 비율   \n",
    "EPOCHS = 20   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a14b6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 좋아하는 감정을 후유증이 있기 아니라 만나세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋아하는 감정을 후유증이 있기 아니라 만나세요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c95d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 헤어졌어.\n",
      "출력 : 좋은 만남이었길 바라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 만남이었길 바라요 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82b674c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 크리스마스인데 만나자고 해도 됨?\n",
      "출력 : 사람마다 필요한 거 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사람마다 필요한 거 같아요 .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('크리스마스인데 만나자고 해도 됨?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28e18355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 맛있게 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있게 드세요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4bab7de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 심심해.\n",
      "출력 : 맛있게 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있게 드세요 .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 심심해.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9acb949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 저녁 뭐 먹을까?\n",
      "출력 : 맛있게 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있게 드세요 .'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 저녁 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5edbb0",
   "metadata": {},
   "source": [
    "### 임의 문장 test 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a67752",
   "metadata": {},
   "source": [
    "d_model을 lr, model 모두 512로 맞춤   \n",
    "드롭아웃 0.3   \n",
    "epochs = 30  \n",
    "Epoch 30/30\n",
    "185/185 [==============================] - 40s 217ms/step - loss: 0.5576 - accuracy: 0.0729   \n",
    "문장이 어색한 건 없지만 질문에 대답이 맞는지는 잘 모르겠다  \n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.3 # 드롭아웃의 비율   \n",
    "EPOCHS = 30   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5272e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 금방 지나갈 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'금방 지나갈 거예요 .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca20704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 헤어졌어.\n",
      "출력 : 많이 시간이 흘렀네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'많이 시간이 흘렀네요 .'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "238f03dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 크리스마스인데 만나자고 해도 됨?\n",
      "출력 : 먼저 물어보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'먼저 물어보세요 .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('크리스마스인데 만나자고 해도 됨?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43fa36c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 저도 듣고 싶네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 듣고 싶네요 .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec85b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 심심해.\n",
      "출력 : 저도 듣고 싶네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 듣고 싶네요 .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 심심해.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e3d3d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 저녁 뭐 먹을까?\n",
      "출력 : 이렇게 고민하게 만들려고 그랬나봐요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이렇게 고민하게 만들려고 그랬나봐요 .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 저녁 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621548a",
   "metadata": {},
   "source": [
    "### 임의 문장 test 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cf5e8",
   "metadata": {},
   "source": [
    "d_model을 lr, model 모두 768로 맞춤   \n",
    "num_layer를 8로 증가, num_heads 를 12로 증가   \n",
    "lr - warmup_steps=4000 -> 8000 으로 증가\n",
    "\n",
    "막상 훈련을 돌리고 보니 데이터가 적은편인데 너무 과하게 파라미터를 설정한 것 같다  \n",
    "\n",
    "Epoch 30/30\n",
    "185/185 [==============================] - 85s 459ms/step - loss: 0.7089 - accuracy: 0.0601   \n",
    "\n",
    "역시나 너무 과했던 것 같다  \n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 8 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 768 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 12 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.3 # 드롭아웃의 비율   \n",
    "EPOCHS = 30   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cdfb21ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑기사 해주는 짝남.\n",
      "출력 : 저도 좀 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 좀 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 곳으로 '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f52dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 헤어졌어.\n",
      "출력 : 많이 많이 많이 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'많이 많이 많이 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6674e2",
   "metadata": {},
   "source": [
    "### 회고\n",
    "실험을 더 해봐야겠지만 현재로써는 5, 6 번이 그나마 결과가 가장 나은 것 같습니다.   \n",
    "아무래도 데이터 양이 많지 않아서 결과가 계속 아쉽게 나오는 것 같습니다.   \n",
    "나중에 더 큰 데이터로도 한 번 수행해보고 싶습니다.   \n",
    "또한 실험을 수행하면서 트렌스포머 구조에 대한 개념이 계속 헷갈려서 정리가 필요할 것 같습니다.   \n",
    "그래도 오늘은 저번보다는 많은 실험을 할 수가 있어 좋았습니다.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
