{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# base line","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import imdb\n(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\ntrain_data = vectorize_sequences(train_data)\n\nmodel = keras.Sequential([\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])\nhistory_original = model.fit(train_data, train_labels,\n                            epochs=20, batch_size=512, validation_split=0.4)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T12:28:55.797558Z","iopub.execute_input":"2025-01-23T12:28:55.798027Z","iopub.status.idle":"2025-01-23T12:29:21.862655Z","shell.execute_reply.started":"2025-01-23T12:28:55.797992Z","shell.execute_reply":"2025-01-23T12:29:21.861046Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\nEpoch 1/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6613 - loss: 0.6305 - val_accuracy: 0.8671 - val_loss: 0.4413\nEpoch 2/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8849 - loss: 0.3822 - val_accuracy: 0.8775 - val_loss: 0.3348\nEpoch 3/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9150 - loss: 0.2643 - val_accuracy: 0.8797 - val_loss: 0.3062\nEpoch 4/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9327 - loss: 0.2082 - val_accuracy: 0.8878 - val_loss: 0.2797\nEpoch 5/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9502 - loss: 0.1646 - val_accuracy: 0.8906 - val_loss: 0.2776\nEpoch 6/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9518 - loss: 0.1477 - val_accuracy: 0.8874 - val_loss: 0.2855\nEpoch 7/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9643 - loss: 0.1221 - val_accuracy: 0.8864 - val_loss: 0.2965\nEpoch 8/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9706 - loss: 0.1082 - val_accuracy: 0.8824 - val_loss: 0.3122\nEpoch 9/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9763 - loss: 0.0879 - val_accuracy: 0.8757 - val_loss: 0.3471\nEpoch 10/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9804 - loss: 0.0786 - val_accuracy: 0.8794 - val_loss: 0.3479\nEpoch 11/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9848 - loss: 0.0671 - val_accuracy: 0.8772 - val_loss: 0.3674\nEpoch 12/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9871 - loss: 0.0595 - val_accuracy: 0.8530 - val_loss: 0.4825\nEpoch 13/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9828 - loss: 0.0600 - val_accuracy: 0.8743 - val_loss: 0.4059\nEpoch 14/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9912 - loss: 0.0413 - val_accuracy: 0.8733 - val_loss: 0.4298\nEpoch 15/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9930 - loss: 0.0382 - val_accuracy: 0.8738 - val_loss: 0.4473\nEpoch 16/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9946 - loss: 0.0321 - val_accuracy: 0.8719 - val_loss: 0.4704\nEpoch 17/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9964 - loss: 0.0258 - val_accuracy: 0.8709 - val_loss: 0.5102\nEpoch 18/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9956 - loss: 0.0254 - val_accuracy: 0.8700 - val_loss: 0.5276\nEpoch 19/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9958 - loss: 0.0220 - val_accuracy: 0.8706 - val_loss: 0.5465\nEpoch 20/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9984 - loss: 0.0146 - val_accuracy: 0.8638 - val_loss: 0.6414\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 사용자 정의 지표","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\nclass F1Score(keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.squeeze(K.cast(y_true, \"float32\"))\n        y_pred = tf.squeeze(K.round(y_pred))\n\n        self.true_positives.assign_add(K.sum(K.cast(y_true * y_pred, \"float32\")))\n        self.false_positives.assign_add(K.sum(K.cast((1 - y_true) * y_pred, \"float32\")))\n        self.false_negatives.assign_add(K.sum(K.cast(y_true * (1 - y_pred), \"float32\")))\n\n    def result(self):\n        precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n        recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n\n        f1_score = 2 * (precision * recall) / (precision + recall + K.epsilon())\n        return f1_score\n\n    def reset_state(self):\n        self.true_positives.assign(0)\n        self.false_positives.assign(0)\n        self.false_negatives.assign(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T13:01:48.292953Z","iopub.execute_input":"2025-01-23T13:01:48.293778Z","iopub.status.idle":"2025-01-23T13:01:48.304718Z","shell.execute_reply.started":"2025-01-23T13:01:48.293712Z","shell.execute_reply":"2025-01-23T13:01:48.303371Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\nn_history = model.fit(train_data, train_labels,\n        epochs=20, batch_size=4, validation_split=0.4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T13:01:48.741756Z","iopub.execute_input":"2025-01-23T13:01:48.742140Z","iopub.status.idle":"2025-01-23T13:06:20.962122Z","shell.execute_reply.started":"2025-01-23T13:01:48.742108Z","shell.execute_reply":"2025-01-23T13:06:20.960821Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8169 - f1_score: 0.8265 - loss: 0.4102 - val_accuracy: 0.8879 - val_f1_score: 0.8864 - val_loss: 0.2905\nEpoch 2/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9175 - f1_score: 0.9188 - loss: 0.2215 - val_accuracy: 0.8942 - val_f1_score: 0.8937 - val_loss: 0.2875\nEpoch 3/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9254 - f1_score: 0.9250 - loss: 0.2060 - val_accuracy: 0.8872 - val_f1_score: 0.8834 - val_loss: 0.3082\nEpoch 4/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9327 - f1_score: 0.9336 - loss: 0.1902 - val_accuracy: 0.8895 - val_f1_score: 0.8884 - val_loss: 0.3255\nEpoch 5/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9372 - f1_score: 0.9375 - loss: 0.1830 - val_accuracy: 0.8904 - val_f1_score: 0.8915 - val_loss: 0.3609\nEpoch 6/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9489 - f1_score: 0.9496 - loss: 0.1597 - val_accuracy: 0.8897 - val_f1_score: 0.8906 - val_loss: 0.3956\nEpoch 7/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9549 - f1_score: 0.9556 - loss: 0.1535 - val_accuracy: 0.8870 - val_f1_score: 0.8873 - val_loss: 0.3925\nEpoch 8/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9594 - f1_score: 0.9601 - loss: 0.1364 - val_accuracy: 0.8826 - val_f1_score: 0.8787 - val_loss: 0.4157\nEpoch 9/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9624 - f1_score: 0.9628 - loss: 0.1223 - val_accuracy: 0.8791 - val_f1_score: 0.8790 - val_loss: 0.4464\nEpoch 10/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9701 - f1_score: 0.9701 - loss: 0.1073 - val_accuracy: 0.8783 - val_f1_score: 0.8802 - val_loss: 0.4798\nEpoch 11/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9748 - f1_score: 0.9749 - loss: 0.0949 - val_accuracy: 0.8766 - val_f1_score: 0.8773 - val_loss: 0.5505\nEpoch 12/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9767 - f1_score: 0.9766 - loss: 0.0857 - val_accuracy: 0.8664 - val_f1_score: 0.8600 - val_loss: 0.5525\nEpoch 13/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9803 - f1_score: 0.9801 - loss: 0.0724 - val_accuracy: 0.8659 - val_f1_score: 0.8599 - val_loss: 0.6434\nEpoch 14/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9810 - f1_score: 0.9810 - loss: 0.0781 - val_accuracy: 0.8630 - val_f1_score: 0.8617 - val_loss: 0.7119\nEpoch 15/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9853 - f1_score: 0.9854 - loss: 0.0620 - val_accuracy: 0.8643 - val_f1_score: 0.8634 - val_loss: 0.7975\nEpoch 16/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9858 - f1_score: 0.9859 - loss: 0.0570 - val_accuracy: 0.8607 - val_f1_score: 0.8564 - val_loss: 0.9485\nEpoch 17/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9907 - f1_score: 0.9907 - loss: 0.0448 - val_accuracy: 0.8627 - val_f1_score: 0.8607 - val_loss: 0.9846\nEpoch 18/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9922 - f1_score: 0.9919 - loss: 0.0396 - val_accuracy: 0.8607 - val_f1_score: 0.8606 - val_loss: 1.0838\nEpoch 19/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9915 - f1_score: 0.9915 - loss: 0.0353 - val_accuracy: 0.8552 - val_f1_score: 0.8491 - val_loss: 1.1596\nEpoch 20/20\n\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9925 - f1_score: 0.9925 - loss: 0.0326 - val_accuracy: 0.8499 - val_f1_score: 0.8396 - val_loss: 1.3203\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\nn_history = model.fit(train_data, train_labels,\n        epochs=20, batch_size=512, validation_split=0.4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T13:06:20.964480Z","iopub.execute_input":"2025-01-23T13:06:20.964813Z","iopub.status.idle":"2025-01-23T13:06:39.169697Z","shell.execute_reply.started":"2025-01-23T13:06:20.964786Z","shell.execute_reply":"2025-01-23T13:06:39.168584Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.6789 - f1_score: 0.7064 - loss: 0.6330 - val_accuracy: 0.8617 - val_f1_score: 0.8649 - val_loss: 0.4484\nEpoch 2/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8750 - f1_score: 0.8774 - loss: 0.4050 - val_accuracy: 0.8817 - val_f1_score: 0.8817 - val_loss: 0.3418\nEpoch 3/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9063 - f1_score: 0.9076 - loss: 0.2930 - val_accuracy: 0.8883 - val_f1_score: 0.8869 - val_loss: 0.2950\nEpoch 4/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9249 - f1_score: 0.9257 - loss: 0.2276 - val_accuracy: 0.8906 - val_f1_score: 0.8901 - val_loss: 0.2772\nEpoch 5/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9414 - f1_score: 0.9423 - loss: 0.1807 - val_accuracy: 0.8901 - val_f1_score: 0.8913 - val_loss: 0.2741\nEpoch 6/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9551 - f1_score: 0.9550 - loss: 0.1513 - val_accuracy: 0.8871 - val_f1_score: 0.8888 - val_loss: 0.2800\nEpoch 7/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9604 - f1_score: 0.9607 - loss: 0.1298 - val_accuracy: 0.8870 - val_f1_score: 0.8851 - val_loss: 0.2889\nEpoch 8/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9658 - f1_score: 0.9660 - loss: 0.1134 - val_accuracy: 0.8822 - val_f1_score: 0.8858 - val_loss: 0.3105\nEpoch 9/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9708 - f1_score: 0.9708 - loss: 0.0994 - val_accuracy: 0.8841 - val_f1_score: 0.8831 - val_loss: 0.3140\nEpoch 10/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9748 - f1_score: 0.9753 - loss: 0.0907 - val_accuracy: 0.8828 - val_f1_score: 0.8817 - val_loss: 0.3289\nEpoch 11/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9802 - f1_score: 0.9803 - loss: 0.0768 - val_accuracy: 0.8777 - val_f1_score: 0.8735 - val_loss: 0.3576\nEpoch 12/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9845 - f1_score: 0.9847 - loss: 0.0659 - val_accuracy: 0.8791 - val_f1_score: 0.8780 - val_loss: 0.3643\nEpoch 13/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9868 - f1_score: 0.9868 - loss: 0.0570 - val_accuracy: 0.8759 - val_f1_score: 0.8787 - val_loss: 0.3921\nEpoch 14/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9857 - f1_score: 0.9858 - loss: 0.0568 - val_accuracy: 0.8750 - val_f1_score: 0.8713 - val_loss: 0.4147\nEpoch 15/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9922 - f1_score: 0.9923 - loss: 0.0435 - val_accuracy: 0.8746 - val_f1_score: 0.8750 - val_loss: 0.4240\nEpoch 16/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9938 - f1_score: 0.9938 - loss: 0.0363 - val_accuracy: 0.8726 - val_f1_score: 0.8724 - val_loss: 0.4479\nEpoch 17/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9939 - f1_score: 0.9939 - loss: 0.0338 - val_accuracy: 0.8588 - val_f1_score: 0.8679 - val_loss: 0.5574\nEpoch 18/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9922 - f1_score: 0.9924 - loss: 0.0351 - val_accuracy: 0.8717 - val_f1_score: 0.8717 - val_loss: 0.4928\nEpoch 19/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9955 - f1_score: 0.9955 - loss: 0.0243 - val_accuracy: 0.8721 - val_f1_score: 0.8715 - val_loss: 0.5139\nEpoch 20/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9973 - f1_score: 0.9973 - loss: 0.0203 - val_accuracy: 0.8700 - val_f1_score: 0.8699 - val_loss: 0.5402\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# batch_size에 따라 tp가 달라진다...!","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}