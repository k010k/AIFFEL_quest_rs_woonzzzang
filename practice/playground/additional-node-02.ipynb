{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# base line","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import imdb\n(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\ntrain_data = vectorize_sequences(train_data)\n\nmodel = keras.Sequential([\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])\nhistory_original = model.fit(train_data, train_labels,\n                            epochs=20, batch_size=512, validation_split=0.4)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:26:37.320472Z","iopub.execute_input":"2025-01-23T06:26:37.320813Z","iopub.status.idle":"2025-01-23T06:27:00.732742Z","shell.execute_reply.started":"2025-01-23T06:26:37.320789Z","shell.execute_reply":"2025-01-23T06:27:00.731577Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6889 - loss: 0.6108 - val_accuracy: 0.8721 - val_loss: 0.4005\nEpoch 2/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8936 - loss: 0.3482 - val_accuracy: 0.8847 - val_loss: 0.3116\nEpoch 3/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9115 - loss: 0.2570 - val_accuracy: 0.8916 - val_loss: 0.2810\nEpoch 4/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9395 - loss: 0.1971 - val_accuracy: 0.8853 - val_loss: 0.2804\nEpoch 5/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9499 - loss: 0.1617 - val_accuracy: 0.8862 - val_loss: 0.2809\nEpoch 6/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9548 - loss: 0.1382 - val_accuracy: 0.8811 - val_loss: 0.2997\nEpoch 7/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9655 - loss: 0.1182 - val_accuracy: 0.8820 - val_loss: 0.3087\nEpoch 8/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9691 - loss: 0.1076 - val_accuracy: 0.8781 - val_loss: 0.3223\nEpoch 9/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9744 - loss: 0.0936 - val_accuracy: 0.8725 - val_loss: 0.3602\nEpoch 10/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9773 - loss: 0.0809 - val_accuracy: 0.8771 - val_loss: 0.3599\nEpoch 11/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9835 - loss: 0.0667 - val_accuracy: 0.8794 - val_loss: 0.3591\nEpoch 12/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9861 - loss: 0.0585 - val_accuracy: 0.8743 - val_loss: 0.3962\nEpoch 13/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9876 - loss: 0.0520 - val_accuracy: 0.8773 - val_loss: 0.3999\nEpoch 14/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9901 - loss: 0.0439 - val_accuracy: 0.8734 - val_loss: 0.4330\nEpoch 15/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9921 - loss: 0.0387 - val_accuracy: 0.8744 - val_loss: 0.4467\nEpoch 16/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0332 - val_accuracy: 0.8732 - val_loss: 0.4707\nEpoch 17/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9945 - loss: 0.0304 - val_accuracy: 0.8734 - val_loss: 0.4883\nEpoch 18/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9977 - loss: 0.0208 - val_accuracy: 0.8571 - val_loss: 0.5908\nEpoch 19/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9956 - loss: 0.0250 - val_accuracy: 0.8708 - val_loss: 0.5330\nEpoch 20/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9986 - loss: 0.0148 - val_accuracy: 0.8566 - val_loss: 0.6447\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 사용자 정의 지표","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\nclass F1Score(keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = K.cast(y_true, \"float32\")\n        y_pred = K.round(y_pred)\n\n        self.true_positives.assign_add(K.sum(K.cast(y_true * y_pred, \"float32\")))\n        self.false_positives.assign_add(K.sum(K.cast((1 - y_true) * y_pred, \"float32\")))\n        self.false_negatives.assign_add(K.sum(K.cast(y_true * (1 - y_pred), \"float32\")))\n\n    def result(self):\n        precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n        recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n\n        f1_score = 2 * (precision * recall) / (precision + recall + K.epsilon())\n        return f1_score\n\n    def reset_state(self):\n        self.true_positives.assign(0)\n        self.false_positives.assign(0)\n        self.false_negatives.assign(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:47:02.022650Z","iopub.execute_input":"2025-01-23T06:47:02.023059Z","iopub.status.idle":"2025-01-23T06:47:02.031973Z","shell.execute_reply.started":"2025-01-23T06:47:02.023025Z","shell.execute_reply":"2025-01-23T06:47:02.030688Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\nn_history = model.fit(train_data, train_labels,\n        epochs=20, batch_size=512, validation_split=0.4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:47:05.778055Z","iopub.execute_input":"2025-01-23T06:47:05.778440Z","iopub.status.idle":"2025-01-23T06:47:34.691622Z","shell.execute_reply.started":"2025-01-23T06:47:05.778412Z","shell.execute_reply":"2025-01-23T06:47:34.687659Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9901 - f1_score: 0.5027 - loss: 0.0275 - val_accuracy: 0.9317 - val_f1_score: 0.5005 - val_loss: 0.3471\nEpoch 2/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9994 - f1_score: 0.5027 - loss: 0.0061 - val_accuracy: 0.9305 - val_f1_score: 0.5018 - val_loss: 0.3643\nEpoch 3/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9997 - f1_score: 0.4984 - loss: 0.0042 - val_accuracy: 0.9293 - val_f1_score: 0.5009 - val_loss: 0.3784\nEpoch 4/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9990 - f1_score: 0.5015 - loss: 0.0057 - val_accuracy: 0.9292 - val_f1_score: 0.5000 - val_loss: 0.3871\nEpoch 5/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 0.5036 - loss: 0.0026 - val_accuracy: 0.9278 - val_f1_score: 0.5000 - val_loss: 0.3996\nEpoch 6/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - f1_score: 0.5042 - loss: 0.0025 - val_accuracy: 0.9264 - val_f1_score: 0.4928 - val_loss: 0.4185\nEpoch 7/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9993 - f1_score: 0.5075 - loss: 0.0037 - val_accuracy: 0.9248 - val_f1_score: 0.5025 - val_loss: 0.4298\nEpoch 8/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9999 - f1_score: 0.5046 - loss: 0.0016 - val_accuracy: 0.9251 - val_f1_score: 0.4978 - val_loss: 0.4380\nEpoch 9/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 0.5042 - loss: 0.0014 - val_accuracy: 0.9175 - val_f1_score: 0.5104 - val_loss: 0.4812\nEpoch 10/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9970 - f1_score: 0.5021 - loss: 0.0098 - val_accuracy: 0.9228 - val_f1_score: 0.5000 - val_loss: 0.4617\nEpoch 11/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 1.0000 - f1_score: 0.5006 - loss: 0.0010 - val_accuracy: 0.9216 - val_f1_score: 0.4999 - val_loss: 0.4758\nEpoch 12/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9997 - f1_score: 0.5049 - loss: 0.0019 - val_accuracy: 0.9221 - val_f1_score: 0.4977 - val_loss: 0.4862\nEpoch 13/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - f1_score: 0.5065 - loss: 8.5672e-04 - val_accuracy: 0.9207 - val_f1_score: 0.5021 - val_loss: 0.4970\nEpoch 14/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - f1_score: 0.5043 - loss: 7.2449e-04 - val_accuracy: 0.9200 - val_f1_score: 0.5054 - val_loss: 0.5162\nEpoch 15/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9999 - f1_score: 0.5047 - loss: 9.8396e-04 - val_accuracy: 0.9200 - val_f1_score: 0.5055 - val_loss: 0.5216\nEpoch 16/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - f1_score: 0.5082 - loss: 5.9851e-04 - val_accuracy: 0.9199 - val_f1_score: 0.5001 - val_loss: 0.5243\nEpoch 17/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 0.4992 - loss: 4.8095e-04 - val_accuracy: 0.9195 - val_f1_score: 0.4998 - val_loss: 0.5405\nEpoch 18/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9999 - f1_score: 0.5032 - loss: 9.2656e-04 - val_accuracy: 0.9182 - val_f1_score: 0.5012 - val_loss: 0.5520\nEpoch 19/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 1.0000 - f1_score: 0.5053 - loss: 3.7164e-04 - val_accuracy: 0.9177 - val_f1_score: 0.5020 - val_loss: 0.5611\nEpoch 20/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 1.0000 - f1_score: 0.4989 - loss: 3.2040e-04 - val_accuracy: 0.9144 - val_f1_score: 0.4902 - val_loss: 0.5776\n","output_type":"stream"}],"execution_count":17}]}