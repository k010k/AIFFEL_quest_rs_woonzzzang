{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# base line","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import imdb\n(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\ntrain_data = vectorize_sequences(train_data)\n\nmodel = keras.Sequential([\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])\nhistory_original = model.fit(train_data, train_labels,\n                            epochs=20, batch_size=512, validation_split=0.4)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:51:26.550902Z","iopub.execute_input":"2025-01-23T07:51:26.551275Z","iopub.status.idle":"2025-01-23T07:51:51.030740Z","shell.execute_reply.started":"2025-01-23T07:51:26.551232Z","shell.execute_reply":"2025-01-23T07:51:51.029662Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6794 - loss: 0.6007 - val_accuracy: 0.8338 - val_loss: 0.4195\nEpoch 2/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8875 - loss: 0.3393 - val_accuracy: 0.8832 - val_loss: 0.3116\nEpoch 3/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9232 - loss: 0.2444 - val_accuracy: 0.8861 - val_loss: 0.2856\nEpoch 4/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9351 - loss: 0.1970 - val_accuracy: 0.8909 - val_loss: 0.2765\nEpoch 5/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9501 - loss: 0.1563 - val_accuracy: 0.8903 - val_loss: 0.2782\nEpoch 6/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9614 - loss: 0.1294 - val_accuracy: 0.8856 - val_loss: 0.2878\nEpoch 7/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9659 - loss: 0.1145 - val_accuracy: 0.8824 - val_loss: 0.3049\nEpoch 8/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9708 - loss: 0.0983 - val_accuracy: 0.8792 - val_loss: 0.3250\nEpoch 9/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9796 - loss: 0.0781 - val_accuracy: 0.8814 - val_loss: 0.3326\nEpoch 10/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9857 - loss: 0.0655 - val_accuracy: 0.8745 - val_loss: 0.3691\nEpoch 11/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9861 - loss: 0.0595 - val_accuracy: 0.8725 - val_loss: 0.3949\nEpoch 12/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9868 - loss: 0.0531 - val_accuracy: 0.8801 - val_loss: 0.3872\nEpoch 13/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9918 - loss: 0.0410 - val_accuracy: 0.8778 - val_loss: 0.4094\nEpoch 14/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9946 - loss: 0.0329 - val_accuracy: 0.8752 - val_loss: 0.4343\nEpoch 15/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9919 - loss: 0.0330 - val_accuracy: 0.8753 - val_loss: 0.4553\nEpoch 16/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9953 - loss: 0.0255 - val_accuracy: 0.8744 - val_loss: 0.4724\nEpoch 17/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9977 - loss: 0.0191 - val_accuracy: 0.8726 - val_loss: 0.4992\nEpoch 18/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9986 - loss: 0.0159 - val_accuracy: 0.8727 - val_loss: 0.5172\nEpoch 19/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9969 - loss: 0.0189 - val_accuracy: 0.8727 - val_loss: 0.5403\nEpoch 20/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.0144 - val_accuracy: 0.8711 - val_loss: 0.5631\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 사용자 정의 지표","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\nclass F1Score(keras.metrics.Metric):\n    def __init__(self, name=\"f1_score\", **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = K.cast(y_true, \"float32\")\n        y_pred = K.round(y_pred)\n\n        self.true_positives.assign_add(K.sum(K.cast(y_true * y_pred, \"float32\")))\n        self.false_positives.assign_add(K.sum(K.cast((1 - y_true) * y_pred, \"float32\")))\n        self.false_negatives.assign_add(K.sum(K.cast(y_true * (1 - y_pred), \"float32\")))\n\n    def result(self):\n        precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n        recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n\n        f1_score = 2 * (precision * recall) / (precision + recall + K.epsilon())\n        return f1_score\n\n    def reset_state(self):\n        self.true_positives.assign(0)\n        self.false_positives.assign(0)\n        self.false_negatives.assign(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:51:51.032334Z","iopub.execute_input":"2025-01-23T07:51:51.032665Z","iopub.status.idle":"2025-01-23T07:51:51.041796Z","shell.execute_reply.started":"2025-01-23T07:51:51.032637Z","shell.execute_reply":"2025-01-23T07:51:51.040407Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(16, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\", F1Score()])\nn_history = model.fit(train_data, train_labels,\n        epochs=20, batch_size=512, validation_split=0.4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:51:51.043995Z","iopub.execute_input":"2025-01-23T07:51:51.044334Z","iopub.status.idle":"2025-01-23T07:52:07.415608Z","shell.execute_reply.started":"2025-01-23T07:51:51.044301Z","shell.execute_reply":"2025-01-23T07:52:07.414295Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6681 - f1_score: 0.5916 - loss: 0.6302 - val_accuracy: 0.8567 - val_f1_score: 0.4801 - val_loss: 0.4481\nEpoch 2/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8832 - f1_score: 0.5061 - loss: 0.3929 - val_accuracy: 0.8792 - val_f1_score: 0.5128 - val_loss: 0.3406\nEpoch 3/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9097 - f1_score: 0.5130 - loss: 0.2858 - val_accuracy: 0.8828 - val_f1_score: 0.4887 - val_loss: 0.3009\nEpoch 4/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9242 - f1_score: 0.5052 - loss: 0.2291 - val_accuracy: 0.8901 - val_f1_score: 0.4990 - val_loss: 0.2789\nEpoch 5/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9402 - f1_score: 0.5058 - loss: 0.1867 - val_accuracy: 0.8769 - val_f1_score: 0.5311 - val_loss: 0.3034\nEpoch 6/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9461 - f1_score: 0.5038 - loss: 0.1646 - val_accuracy: 0.8892 - val_f1_score: 0.5030 - val_loss: 0.2768\nEpoch 7/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9565 - f1_score: 0.5074 - loss: 0.1375 - val_accuracy: 0.8826 - val_f1_score: 0.5200 - val_loss: 0.2973\nEpoch 8/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9643 - f1_score: 0.5066 - loss: 0.1184 - val_accuracy: 0.8832 - val_f1_score: 0.4850 - val_loss: 0.3013\nEpoch 9/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9691 - f1_score: 0.5022 - loss: 0.1066 - val_accuracy: 0.8788 - val_f1_score: 0.5218 - val_loss: 0.3220\nEpoch 10/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9751 - f1_score: 0.5054 - loss: 0.0929 - val_accuracy: 0.8821 - val_f1_score: 0.4933 - val_loss: 0.3199\nEpoch 11/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9760 - f1_score: 0.5046 - loss: 0.0853 - val_accuracy: 0.8795 - val_f1_score: 0.5078 - val_loss: 0.3353\nEpoch 12/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9839 - f1_score: 0.5039 - loss: 0.0701 - val_accuracy: 0.8778 - val_f1_score: 0.5092 - val_loss: 0.3531\nEpoch 13/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9864 - f1_score: 0.4987 - loss: 0.0625 - val_accuracy: 0.8785 - val_f1_score: 0.4956 - val_loss: 0.3708\nEpoch 14/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9881 - f1_score: 0.5066 - loss: 0.0559 - val_accuracy: 0.8775 - val_f1_score: 0.5066 - val_loss: 0.3904\nEpoch 15/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9895 - f1_score: 0.5082 - loss: 0.0493 - val_accuracy: 0.8767 - val_f1_score: 0.4955 - val_loss: 0.4086\nEpoch 16/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9925 - f1_score: 0.5051 - loss: 0.0416 - val_accuracy: 0.8752 - val_f1_score: 0.4965 - val_loss: 0.4270\nEpoch 17/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9929 - f1_score: 0.4998 - loss: 0.0377 - val_accuracy: 0.8730 - val_f1_score: 0.5078 - val_loss: 0.4505\nEpoch 18/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9942 - f1_score: 0.5090 - loss: 0.0322 - val_accuracy: 0.8718 - val_f1_score: 0.4949 - val_loss: 0.4701\nEpoch 19/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9960 - f1_score: 0.5016 - loss: 0.0266 - val_accuracy: 0.8708 - val_f1_score: 0.4904 - val_loss: 0.4966\nEpoch 20/20\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9970 - f1_score: 0.5055 - loss: 0.0233 - val_accuracy: 0.8713 - val_f1_score: 0.4956 - val_loss: 0.5155\n","output_type":"stream"}],"execution_count":4}]}