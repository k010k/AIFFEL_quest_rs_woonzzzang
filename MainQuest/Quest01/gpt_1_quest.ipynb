{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Transformer와 비교해 변경이 필요한 부분]\n",
    "- Positional Encoding 대신 Positional Embedding 사용\n",
    "- 인코더 삭제\n",
    "    - 인코더 디코더 어텐션 삭제\n",
    "- input 데이터 형식 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 포지셔널 행렬 구현 -> Positional Embedding 으로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 임베딩 레이어\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_seq_len, d_model):\n",
    "        super().__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=max_seq_len, \n",
    "            output_dim=d_model,\n",
    "            input_length=max_seq_len\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
    "        positions = tf.expand_dims(positions, axis=0)\n",
    "        positions = tf.broadcast_to(positions, [tf.shape(x)[0], tf.shape(x)[1]])\n",
    "        return self.embedding(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value) \n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look ahead masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder (삭제 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 인코더 하나의 레이어를 함수로 구현.\n",
    "# # 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "# def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "#   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "#   # 패딩 마스크 사용\n",
    "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "#   # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "#   attention = MultiHeadAttention(\n",
    "#       d_model, num_heads, name=\"attention\")({\n",
    "#           'query': inputs,\n",
    "#           'key': inputs,\n",
    "#           'value': inputs,\n",
    "#           'mask': padding_mask\n",
    "#       })\n",
    "\n",
    "#   # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "#   attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "#   attention = tf.keras.layers.LayerNormalization(\n",
    "#       epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "#   # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "#   outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "#   outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "#   # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "#   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "#   outputs = tf.keras.layers.LayerNormalization(\n",
    "#       epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "#   return tf.keras.Model(\n",
    "#       inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encoder(vocab_size,\n",
    "#             num_layers,\n",
    "#             units,\n",
    "#             d_model,\n",
    "#             num_heads,\n",
    "#             dropout,\n",
    "#             name=\"encoder\"):\n",
    "#   inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "#   # 패딩 마스크 사용\n",
    "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "#   # 임베딩 레이어\n",
    "#   embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "#   embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "#   # 포지셔널 인코딩\n",
    "#   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "#   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "#   # num_layers만큼 쌓아올린 인코더의 층.\n",
    "#   for i in range(num_layers):\n",
    "#     outputs = encoder_layer(\n",
    "#         units=units,\n",
    "#         d_model=d_model,\n",
    "#         num_heads=num_heads,\n",
    "#         dropout=dropout,\n",
    "#         name=\"encoder_layer_{}\".format(i),\n",
    "#     )([outputs, padding_mask])\n",
    "\n",
    "#   return tf.keras.Model(\n",
    "#       inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder (Encoder-decoder attention 제거)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "  \n",
    "# Encoder와 연결되는 Encoder-decoder attention은 제거\n",
    "\n",
    "#   # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "#   attention2 = MultiHeadAttention(\n",
    "#       d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "#           'query': attention1,\n",
    "#           'key': enc_outputs,\n",
    "#           'value': enc_outputs,\n",
    "#           'mask': padding_mask\n",
    "#       })\n",
    "\n",
    "#   # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "#   # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "#   attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "#   attention2 = tf.keras.layers.LayerNormalization(\n",
    "#       epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention1) # 두 번째 attention 층이 없어졌으므로 첫 번째 attention층 결과와와 연결\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs) # 기존 outputs + attention2 에서 attention2를 지움움\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"data/ChatbotData.csv\")\n",
    "\n",
    "# 각각 저장\n",
    "df[\"Q\"].to_csv(\"data/question.txt\", index=False, header=False)\n",
    "df[\"A\"].to_csv(\"data/answer.txt\", index=False, header=False)\n",
    "df[\"label\"].to_csv(\"data/label.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath(\"data\")\n",
    "\n",
    "# 저장된 파일 경로 출력\n",
    "question_path = os.path.join(base_path, \"question.txt\")\n",
    "answer_path = os.path.join(base_path, \"answer.txt\")\n",
    "label_path = os.path.join(base_path, \"label.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 그리 크지는 않아서 따로 샘플 최대 개수를 설정하지는 않겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 함수\n",
    "- 질문과 답변을 하나의 시퀀스로 결합\n",
    "    - \"Q + Delim + A\" 형태로 변환\n",
    "- 시퀀스 앞뒤에 특수 토큰 추가\n",
    "    - (Start) + Q + Delim + A + (Extract)\n",
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장 크기 (Vocab Size): 50257\n",
      "입력 shape: (16, 49)\n",
      "타겟 shape: (16, 49)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# 토크나이저 로드 (GPT2 토크나이저 사용)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # PAD 토큰 설정\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('data/ChatbotData.csv')  # CSV 파일 경로를 지정해주세요\n",
    "\n",
    "# Q와 A를 결합하여 하나의 시퀀스로 만들기\n",
    "text_samples = []\n",
    "for q, a in zip(df['Q'], df['A']):\n",
    "    # Q와 A를 구분자로 구분하여 결합\n",
    "    combined_text = f\"{q} <|sep|> {a}\"\n",
    "    text_samples.append(combined_text)\n",
    "\n",
    "def encode_and_pad(sentences, max_length=50):\n",
    "    \"\"\"\n",
    "    문장을 토큰화하고 정수 인코딩한 후, 패딩을 적용하는 함수\n",
    "    \"\"\"\n",
    "    encoded = tokenizer(sentences, \n",
    "                       padding=\"max_length\",\n",
    "                       truncation=True,\n",
    "                       max_length=max_length,\n",
    "                       return_tensors=\"tf\")  # TensorFlow tensor로 반환\n",
    "    return encoded.input_ids\n",
    "\n",
    "# 토큰화 + 정수 인코딩 + 패딩 적용\n",
    "max_seq_len = 50\n",
    "input_ids = encode_and_pad(text_samples, max_length=max_seq_len)\n",
    "\n",
    "# 데이터셋 생성\n",
    "def create_gpt_dataset(input_ids, batch_size=16):\n",
    "    \"\"\"\n",
    "    GPT 학습을 위한 데이터셋 생성\n",
    "    입력: 현재 토큰\n",
    "    출력: 다음 토큰\n",
    "    \"\"\"\n",
    "    # 입력과 타겟 생성\n",
    "    def create_input_target(sequence):\n",
    "        input_seq = sequence[:-1]  # 마지막 토큰을 제외한 모든 토큰\n",
    "        target_seq = sequence[1:]  # 첫 토큰을 제외한 모든 토큰\n",
    "        return input_seq, target_seq\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tf.cast(input_ids, tf.int32))\n",
    "    dataset = dataset.map(create_input_target)\n",
    "    dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = create_gpt_dataset(input_ids)\n",
    "\n",
    "# 단어장 크기 확인\n",
    "vocab_size = len(tokenizer)\n",
    "print(f\"단어장 크기 (Vocab Size): {vocab_size}\")\n",
    "\n",
    "# 데이터셋 확인\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(f\"입력 shape: {input_example.shape}\")\n",
    "    print(f\"타겟 shape: {target_example.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 배치 크기: (16, 49)\n",
      "타겟 배치 크기: (16, 49)\n",
      "입력 배치 예시(첫 샘플): [  169   227   242   167   254   230   167   117   226   168   254   226\n",
      " 31619   111   120   220   166   110   234 23821   245   228   168   244\n",
      "   112  1279    91   325    79    91    29 23821   254   222   167   252\n",
      "   239 23821   251   112   168   243   120   166   116   108   220 47991\n",
      "   112]\n",
      "타겟 배치 예시(첫 샘플): [  227   242   167   254   230   167   117   226   168   254   226 31619\n",
      "   111   120   220   166   110   234 23821   245   228   168   244   112\n",
      "  1279    91   325    79    91    29 23821   254   222   167   252   239\n",
      " 23821   251   112   168   243   120   166   116   108   220 47991   112\n",
      "   168]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_gpt_dataset(input_ids, batch_size=16):\n",
    "    \"\"\"\n",
    "    GPT 학습을 위한 데이터셋 생성\n",
    "    (입력: sequence[:, :-1], 타겟: sequence[:, 1:])\n",
    "    \"\"\"\n",
    "    def map_input_target(sequence):\n",
    "        # 마지막 토큰 제외한 것이 입력, 첫 번째 토큰 제외한 것이 타겟\n",
    "        return sequence[:-1], sequence[1:]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tf.cast(input_ids, tf.int32))\n",
    "\n",
    "    # (입력, 타겟) 쌍으로 만들기\n",
    "    dataset = dataset.map(map_input_target)\n",
    "\n",
    "    # 섞기 + 배치 + Prefetch\n",
    "    dataset = dataset.shuffle(buffer_size=len(input_ids))\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# 예시\n",
    "batch_size = 16\n",
    "dataset = create_gpt_dataset(input_ids, batch_size=batch_size)\n",
    "\n",
    "for input_batch, target_batch in dataset.take(1):\n",
    "    print(\"입력 배치 크기:\", input_batch.shape)\n",
    "    print(\"타겟 배치 크기:\", target_batch.shape)\n",
    "    print(\"입력 배치 예시(첫 샘플):\", input_batch[0].numpy())\n",
    "    print(\"타겟 배치 예시(첫 샘플):\", target_batch[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "입력 shape: (16, 49)\n",
      "타겟 shape: (16, 49)\n"
     ]
    }
   ],
   "source": [
    "# 최종적으로 model.fit()에 넣을 dataset\n",
    "for sample in dataset.take(1):\n",
    "    print(len(sample))  # 튜플 길이 확인 → 2여야 (입력, 타겟)임\n",
    "\n",
    "    # (입력, 타겟)이라면,\n",
    "    # sample[0]: 입력 텐서, sample[1]: 타겟 텐서\n",
    "    print(f\"입력 shape: {sample[0].shape}\")\n",
    "    print(f\"타겟 shape: {sample[1].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교사 강요 사용 (안 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64\n",
    "# BUFFER_SIZE = 20000\n",
    "\n",
    "# # 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# # 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     {\n",
    "#         'inputs': questions,\n",
    "#         'dec_inputs': answers[:, :-1]\n",
    "#     },\n",
    "#     {\n",
    "#         'outputs': answers[:, 1:]\n",
    "#     },\n",
    "# ))\n",
    "\n",
    "# dataset = dataset.cache()\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "# dataset = dataset.batch(BATCH_SIZE)\n",
    "# dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의 및 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(d_ff, activation='relu'),  # Feed-Forward Network\n",
    "            tf.keras.layers.Dense(d_model)  # 차원 축소\n",
    "        ])\n",
    "        self.ln1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ln2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, mask, training):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        mask: Look-Ahead Mask\n",
    "        training: 학습 여부\n",
    "        \"\"\"\n",
    "        # 1️. Self-Attention + Residual Connection\n",
    "        attn_output = self.mha(x, x, attention_mask=mask)  # Self-Attention\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.ln1(x + attn_output)  # Residual + LayerNorm\n",
    "\n",
    "        # 2️. FFN + Residual Connection\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.ln2(out1 + ffn_output)  # Residual + LayerNorm\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT1(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, max_seq_len, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model)\n",
    "        self.positional_embedding = PositionalEmbedding(max_seq_len, d_model)\n",
    "\n",
    "        self.transformer_blocks = [\n",
    "            TransformerDecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.ln_f = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.fc_out = tf.keras.layers.Dense(vocab_size, activation='softmax')  # 최종 출력\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 패딩 마스크 및 룩 어헤드 마스크 생성\n",
    "        padding_mask = create_padding_mask(x)\n",
    "        look_ahead_mask = create_look_ahead_mask(x)\n",
    "\n",
    "        # 임베딩 적용 ('토큰 + 포지션 임베딩'을 입력으로 사용)\n",
    "        tok_emb = self.token_embedding(x)  # (batch_size, seq_len, d_model)\n",
    "        pos_emb = self.positional_embedding(x)  # (1, seq_len, d_model)\n",
    "        x = tok_emb + pos_emb  # 두 개 더해서 최종 입력 만듦\n",
    "\n",
    "        # Transformer 블록 적용\n",
    "        for layer in self.transformer_blocks:\n",
    "            x = layer(x, look_ahead_mask, training)  # 마스킹 적용\n",
    "\n",
    "        x = self.ln_f(x)  # 마지막 LayerNorm\n",
    "        logits = self.fc_out(x)  # (batch_size, seq_len, vocab_size)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt1_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    multiple                  38597376  \n",
      "                                                                 \n",
      " positional_embedding_5 (Po  multiple                  38400     \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 60 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 61 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 62 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 63 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 64 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 65 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 66 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 67 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 68 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 69 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 70 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " transformer_decoder_layer_  multiple                  33065472  \n",
      " 71 (TransformerDecoderLaye                                      \n",
      " r)                                                              \n",
      "                                                                 \n",
      " layer_normalization_149 (L  multiple                  1536      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " dense_149 (Dense)           multiple                  38647633  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 474070609 (1.77 GB)\n",
      "Trainable params: 474070609 (1.77 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "vocab_size = 50257  # 어휘 사전 크기\n",
    "num_layers = 12  # 디코더 레이어 개수\n",
    "d_model = 768  # 모델 차원 (GPT-1 기준)\n",
    "num_heads = 12  # 멀티헤드 어텐션 개수\n",
    "d_ff = 3072  # FFN 차원 (GPT-1 논문 기준)\n",
    "dropout = 0.1  # 드롭아웃 비율\n",
    "max_seq_len = 50  # 최대 문장 길이\n",
    "\n",
    "# GPT 모델 인스턴스 생성\n",
    "model = GPT1(\n",
    "    vocab_size=vocab_size,\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=d_ff,\n",
    "    dropout=dropout,\n",
    "    max_seq_len=max_seq_len,\n",
    ")\n",
    "\n",
    "# 모델을 빌드 (입력 shape 명시)\n",
    "model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "# 모델 구조 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embedding_6, Parameters: 38597376\n",
      "Layer: positional_embedding_3, Parameters: 38400\n",
      "Layer: transformer_decoder_layer_36, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_37, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_38, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_39, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_40, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_41, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_42, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_43, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_44, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_45, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_46, Parameters: 33065472\n",
      "Layer: transformer_decoder_layer_47, Parameters: 33065472\n",
      "Layer: layer_normalization_99, Parameters: 1536\n",
      "Layer: dense_99, Parameters: 38647633\n",
      "Vocab Size: 50257\n"
     ]
    }
   ],
   "source": [
    "# 개별 레이어의 파라미터 수 확인\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer: {layer.name}, Parameters: {layer.count_params()}\")\n",
    "\n",
    "# 어휘 크기 확인\n",
    "print(f\"Vocab Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 커스텀 된 학습률 - 뭔가 오류가 계속 나서 우선 안 쓰는 걸로.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "#   def __init__(self, d_model, warmup_steps=4000):\n",
    "#     super(CustomSchedule, self).__init__()\n",
    "\n",
    "#     self.d_model = d_model\n",
    "#     self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "#     self.warmup_steps = warmup_steps\n",
    "\n",
    "#   def __call__(self, step):\n",
    "#     arg1 = tf.math.rsqrt(step, tf.float32)\n",
    "#     arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "#     return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "# plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "# plt.ylabel(\"Learning Rate\")\n",
    "# plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 손실 함수 및 옵티마이저 설정\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)  # Softmax 적용됨\n",
    "# learning_rate = CustomSchedule(float(d_model))\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# # 모델 컴파일\n",
    "# model.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(\n",
    "#     learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# def accuracy(y_true, y_pred):\n",
    "#   y_true = tf.reshape(y_true, shape=(-1, max_seq_len - 1))\n",
    "#   return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 shape: (16, 49)\n",
      "타겟 shape: (16, 49)\n",
      "입력 샘플: [[  169   247   242   168   252    98 23821    95   222 23821   246   230\n",
      "    168   223   246   166   110   234   220 47991   246   166   111   254\n",
      "  23821   233   114 46695    97  1279    91   325    79    91    29   220\n",
      "  47991   246 46695    97   167   111   112   167   102   112 31619   232\n",
      "    246]\n",
      " [  168   224   112   168   108   238   220   166   109   108   220   166\n",
      "    108   247   168   243   226  1279    91   325    79    91    29   220\n",
      "    166   116   108   167   114   226 35975   120   166   118   120   168\n",
      "    245   238   168   248   242    13 50256 50256 50256 50256 50256 50256\n",
      "  50256]\n",
      " [  169   251   238   168   252   234  4907 31619   114   230   166   116\n",
      "    230 35975   112 46695   115  4907   159   227   254   159   227   254\n",
      "   1279    91   325    79    91    29   220   169   238   230 35975   112\n",
      "    168   243   120 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      "  50256]\n",
      " [  168   117   250   166   113   105 31619   242   108   167   251   120\n",
      "    220   166   108   243   167   224   101   166   108   222   167   224\n",
      "    246  1279    91   325    79    91    29 23821   117   250   166   113\n",
      "    105   166   108   222 31619   242   108   167   251   120   168   246\n",
      "     97]\n",
      " [  168   243   226   166   116   108 23821    95   233   168   243   226\n",
      "  47991   246   167   232   242 31619   224   101   168   252   238 23821\n",
      "    244   112   167   243   234    30  1279    91   325    79    91    29\n",
      "  23821   108   102 47991   254   220   166   109   108   220   166   108\n",
      "    247]\n",
      " [  168   246    97   167   232   246 31619   100   230   168   100   222\n",
      "    167   100   231 23821   251   116   168  8955 47991   246   167   253\n",
      "    105   220   166   108   239 46695   230 46695    97    13  1279    91\n",
      "    325    79    91    29 31619   107   116   167   254   101   168   245\n",
      "    228]\n",
      " [  166   110   108   166   113   255 23821   245   108   167   251   121\n",
      "    169   244   230   168   244   112  1279    91   325    79    91    29\n",
      "  23821   228   235 35975   222   220   169   249   226   167   254   101\n",
      "  47991   246   166   110   254   168   244   112   168   248   242    13\n",
      "  50256]\n",
      " [  168   252   232 35975   222 23821    97   226 23821   243   234   168\n",
      "    243   246   167   232   242   167   235   108  1279    91   325    79\n",
      "     91    29 23821   231   105   168   248   112 23821   251   120 35975\n",
      "    222 23821   243   226 46695   230   168   100   222   168   248   242\n",
      "     13]\n",
      " [  168   232    97   169   226   108   167   242   242   220 47991   246\n",
      "  46695    97 31619   100   234   167  8955   168   244   112  1279    91\n",
      "    325    79    91    29   220   166   111   113   167   114   222   167\n",
      "    232   242 23821   243   230 47991   246   166   111   254     0 50256\n",
      "  50256]\n",
      " [  168  8955   167   252   239 35975   226 31619   107   123   168   250\n",
      "    120   168   226   116   168   248   242    30  1279    91   325    79\n",
      "     91    29 31619   107   123   168   232   113 46695   230 46695    97\n",
      "     13 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      "  50256]\n",
      " [   17   167   227   226   168   100   116 31619   237   247   166   109\n",
      "    108   168    97   239 35975   116   167   235   108   220   166   110\n",
      "    108   169   246   120 47991   246   167   254    97   166   111   254\n",
      "   1279    91   325    79    91    29 23821   226   250   167    94   250\n",
      "    220]\n",
      " [  168    95   233   168   243   226 47991   246   168   100   222 23821\n",
      "    243   232   167   232   242   167   235   108   220   166   111   226\n",
      "    168   228   235 23821   245   108   167   251   121 47991   246   166\n",
      "    111   254 31619   100   234   167   224   246   167   232   242   166\n",
      "    109]\n",
      " [  168   245   108   167   251   121 23821   247   242   167   232   242\n",
      "    167   235   108 31619   223   251   167   225   230   168   244   112\n",
      "   1279    91   325    79    91    29 23821   244   116   168   254   254\n",
      "    166   108   226 23821   246   105 23821   230   250   166   108   226\n",
      "  35975]\n",
      " [   19   167   227   226 23821   245   108   168   243   254   220   169\n",
      "    249   226 23821   251   112   167   111   226   718   166   108   250\n",
      "    168   249   242    13 23821   225   230   167    94   250   168   248\n",
      "    112 23821   233   250   168   252   239 35975   226   220 47991   246\n",
      "    167]\n",
      " [  169   246   226   166   116   230   168   246   223   168   230   246\n",
      "    168    99   251 23821   252   232   168   244   112 31619   101   117\n",
      "    168   245   230   168   244   112  1279    91   325    79    91    29\n",
      "    220   169   233   108   167   223   234 31619   103   101   168   243\n",
      "    226]\n",
      " [  168   245   105   168   252   238   168   117   250   166   113   105\n",
      "    166   108   222 31619   224   246 23821  8955   167   252   239 47991\n",
      "    246   167   232   242   220   166   109   112   168   100   222   220\n",
      "    169   247   243   168   233   254 35975   112 23821   245   228   168\n",
      "    244]]\n",
      "타겟 샘플: [[  247   242   168   252    98 23821    95   222 23821   246   230   168\n",
      "    223   246   166   110   234   220 47991   246   166   111   254 23821\n",
      "    233   114 46695    97  1279    91   325    79    91    29   220 47991\n",
      "    246 46695    97   167   111   112   167   102   112 31619   232   246\n",
      "    168]\n",
      " [  224   112   168   108   238   220   166   109   108   220   166   108\n",
      "    247   168   243   226  1279    91   325    79    91    29   220   166\n",
      "    116   108   167   114   226 35975   120   166   118   120   168   245\n",
      "    238   168   248   242    13 50256 50256 50256 50256 50256 50256 50256\n",
      "  50256]\n",
      " [  251   238   168   252   234  4907 31619   114   230   166   116   230\n",
      "  35975   112 46695   115  4907   159   227   254   159   227   254  1279\n",
      "     91   325    79    91    29   220   169   238   230 35975   112   168\n",
      "    243   120 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      "  50256]\n",
      " [  117   250   166   113   105 31619   242   108   167   251   120   220\n",
      "    166   108   243   167   224   101   166   108   222   167   224   246\n",
      "   1279    91   325    79    91    29 23821   117   250   166   113   105\n",
      "    166   108   222 31619   242   108   167   251   120   168   246    97\n",
      "    166]\n",
      " [  243   226   166   116   108 23821    95   233   168   243   226 47991\n",
      "    246   167   232   242 31619   224   101   168   252   238 23821   244\n",
      "    112   167   243   234    30  1279    91   325    79    91    29 23821\n",
      "    108   102 47991   254   220   166   109   108   220   166   108   247\n",
      "    168]\n",
      " [  246    97   167   232   246 31619   100   230   168   100   222   167\n",
      "    100   231 23821   251   116   168  8955 47991   246   167   253   105\n",
      "    220   166   108   239 46695   230 46695    97    13  1279    91   325\n",
      "     79    91    29 31619   107   116   167   254   101   168   245   228\n",
      "  35975]\n",
      " [  110   108   166   113   255 23821   245   108   167   251   121   169\n",
      "    244   230   168   244   112  1279    91   325    79    91    29 23821\n",
      "    228   235 35975   222   220   169   249   226   167   254   101 47991\n",
      "    246   166   110   254   168   244   112   168   248   242    13 50256\n",
      "  50256]\n",
      " [  252   232 35975   222 23821    97   226 23821   243   234   168   243\n",
      "    246   167   232   242   167   235   108  1279    91   325    79    91\n",
      "     29 23821   231   105   168   248   112 23821   251   120 35975   222\n",
      "  23821   243   226 46695   230   168   100   222   168   248   242    13\n",
      "  50256]\n",
      " [  232    97   169   226   108   167   242   242   220 47991   246 46695\n",
      "     97 31619   100   234   167  8955   168   244   112  1279    91   325\n",
      "     79    91    29   220   166   111   113   167   114   222   167   232\n",
      "    242 23821   243   230 47991   246   166   111   254     0 50256 50256\n",
      "  50256]\n",
      " [ 8955   167   252   239 35975   226 31619   107   123   168   250   120\n",
      "    168   226   116   168   248   242    30  1279    91   325    79    91\n",
      "     29 31619   107   123   168   232   113 46695   230 46695    97    13\n",
      "  50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      "  50256]\n",
      " [  167   227   226   168   100   116 31619   237   247   166   109   108\n",
      "    168    97   239 35975   116   167   235   108   220   166   110   108\n",
      "    169   246   120 47991   246   167   254    97   166   111   254  1279\n",
      "     91   325    79    91    29 23821   226   250   167    94   250   220\n",
      "    166]\n",
      " [   95   233   168   243   226 47991   246   168   100   222 23821   243\n",
      "    232   167   232   242   167   235   108   220   166   111   226   168\n",
      "    228   235 23821   245   108   167   251   121 47991   246   166   111\n",
      "    254 31619   100   234   167   224   246   167   232   242   166   109\n",
      "    108]\n",
      " [  245   108   167   251   121 23821   247   242   167   232   242   167\n",
      "    235   108 31619   223   251   167   225   230   168   244   112  1279\n",
      "     91   325    79    91    29 23821   244   116   168   254   254   166\n",
      "    108   226 23821   246   105 23821   230   250   166   108   226 35975\n",
      "    112]\n",
      " [  167   227   226 23821   245   108   168   243   254   220   169   249\n",
      "    226 23821   251   112   167   111   226   718   166   108   250   168\n",
      "    249   242    13 23821   225   230   167    94   250   168   248   112\n",
      "  23821   233   250   168   252   239 35975   226   220 47991   246   167\n",
      "    232]\n",
      " [  246   226   166   116   230   168   246   223   168   230   246   168\n",
      "     99   251 23821   252   232   168   244   112 31619   101   117   168\n",
      "    245   230   168   244   112  1279    91   325    79    91    29   220\n",
      "    169   233   108   167   223   234 31619   103   101   168   243   226\n",
      "    220]\n",
      " [  245   105   168   252   238   168   117   250   166   113   105   166\n",
      "    108   222 31619   224   246 23821  8955   167   252   239 47991   246\n",
      "    167   232   242   220   166   109   112   168   100   222   220   169\n",
      "    247   243   168   233   254 35975   112 23821   245   228   168   244\n",
      "    112]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "for sample in dataset.take(1):\n",
    "    print(f\"입력 shape: {sample[0].shape}\")\n",
    "    print(f\"타겟 shape: {sample[1].shape}\")\n",
    "    print(f\"입력 샘플: {sample[0].numpy()}\")\n",
    "    print(f\"타겟 샘플: {sample[1].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/downtown/miniconda3/envs/fucklms/lib/python3.8/site-packages/keras/src/backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/738 [>.............................] - ETA: 1:06:03 - loss: 6.5758 - accuracy: 0.0574"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/fucklms/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [회고]\n",
    "학습 돌아가는 것 까지는 확인을 했습니다만,    \n",
    "... 파라미터를 보시면 아시겠지만 너무 과도하게 나와서    \n",
    "학습시간도도 말도 안 되게 나와서 일단 임의로 중지시켰습니다.\n",
    "ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗봇 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decoder_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 문장 test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 코드로 학습시킨 결과  \n",
    "첫 질문은 반대의 대답을 하고 두 번째 질문은 말이 되는 듯 하다  \n",
    "\n",
    "[전처리]    \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수    \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.1 # 드롭아웃의 비율   \n",
    "EPOCHS = 10   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 문장 test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교사 강요에서 BUFFER_SIZE 만 5000으로 수정한 결과  \n",
    "전 보다는 어느 정도 말이 되긴 하지만 그래도 아직 부족하다  \n",
    "acc도 0.06 대  \n",
    "  \n",
    "[전처리]    \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수    \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.1 # 드롭아웃의 비율   \n",
    "EPOCHS = 10   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('혼자 노력하는 연애인 거 같아.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('크리스마스인데 만나자고 해도 됨?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('나 심심해.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 저녁 뭐 먹을까?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 문장 test 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr의 d_model 과 동일하게 128로 맞춤  \n",
    "드롭아웃도 0.5로 키우고  \n",
    "교사 강요 batch_size도 16으로 줄였다  \n",
    "결과는 ..... 처참합니다    \n",
    "그리고 BUFFER SIZE 관련해서 영진님께서 캐시에 있는 데이터를 버퍼에서 셔플하여 데이터의 편향을 막으려고 사용한 것이므로    \n",
    "5000개만 데이터를 섞게 되면 편향이 생길 수 있다는 의견을 공유해주셨다    \n",
    "확실히 결과를 보면 그런 것 같다  \n",
    "따라서 다음 test에는 다시 20000으로 복귀..   \n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.5 # 드롭아웃의 비율   \n",
    "EPOCHS = 10   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 16   \n",
    "BUFFER_SIZE = 5000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 문장 test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "교사 강요 파라미터를 다시 원복하고 에폭만 20으로 늘려봤다   \n",
    "\n",
    "[전처리]   \n",
    "기본 전처리   \n",
    "두점(?.!,) 앞뒤에 공백 추가   \n",
    "연속된 공백을 하나의 공백으로 변환   \n",
    "한글, 영어, 숫자, 기본적인 특수문자(?.!,)만 허용하고 나머지는 공백 처리   \n",
    "\n",
    "[하이퍼파라미터]   \n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수   \n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입, 출력의 고정 차원   \n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기   \n",
    "DROPOUT = 0.5 # 드롭아웃의 비율   \n",
    "EPOCHS = 20   \n",
    "(교사 강요)   \n",
    "BATCH_SIZE = 64   \n",
    "BUFFER_SIZE = 20000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('흑기사 해주는 짝남.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('나 헤어졌어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('크리스마스인데 만나자고 해도 됨?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('나 심심해.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 저녁 뭐 먹을까?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fucklms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
