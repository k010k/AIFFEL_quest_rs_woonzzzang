{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 01:13:14.369135: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-13 01:13:14.371248: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-13 01:13:14.417361: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-13 01:13:14.418434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-13 01:13:14.969114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, 'typeDict'):\n",
    "    np.typeDict = np.sctypeDict\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로\n",
    "path = \"/home/downtown/aiffel/transformer_chatbot/ChatbotData.csv\"\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 'Q' 컬럼은 질문, 'A' 컬럼은 답변으로 분리\n",
    "questions = df['Q'].tolist()\n",
    "answers = df['A'].tolist()\n",
    "\n",
    "# 데이터 확인\n",
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 전처리 함수를 만들어 보세요. 아래 기능을 추가해주세요.\n",
    "def preprocess_sentence(sentence):\n",
    "    # 대문자를 소문자로 변환\n",
    "    # 영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 정규식을 활용하여 모두 제거\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9ㄱ-ㅎ가-힣.,!?]\", \" \", sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'ppl 심하네']\n",
      "['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.']\n"
     ]
    }
   ],
   "source": [
    "questions = list(map(preprocess_sentence, questions))\n",
    "answers = list(map(preprocess_sentence, answers))\n",
    "\n",
    "# 데이터 확인\n",
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰화\n",
    "### 토크나이저 준비\n",
    "토큰화에는 KoNLPy의 mecab 클래스를 사용   \n",
    "\n",
    "아래 조건을 만족하는 build_corpus() 함수 구현   \n",
    "\n",
    "1. 소스 문장 데이터와 타겟 문장 데이터를 입력으로 받습니다. \n",
    "2. 데이터를 앞서 정의한 preprocess_sentence() 함수로 정제하고, 토큰화합니다. \n",
    "3. 토큰화는 전달받은 토크나이즈 함수를 사용합니다. 이번엔 mecab.morphs 함수를 전달하시면 됩니다. \n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외합니다. \n",
    "5. 중복되는 문장은 데이터에서 제외합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요! \n",
    "\n",
    "구현한 함수를 활용하여 questions 와 answers 를 각각 que_corpus , ans_corpus 에 토큰화하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "tokenizer = Okt().morphs\n",
    "\n",
    "def build_corpus(sentences, tokenizer, max_len=50):\n",
    "    \"\"\"\n",
    "    문장 데이터를 토큰화하고, 길이 제한 및 중복 제거하여 정제하는 함수\n",
    "\n",
    "    :param sentences: 입력 문장 리스트\n",
    "    :param tokenizer: 사용할 토크나이저 (예: Okt().morphs)\n",
    "    :param max_len: 최대 토큰 길이 제한 (default: 50)\n",
    "    :return: 토큰화된 문장 리스트 (중복 제거됨)\n",
    "    \"\"\"\n",
    "    processed_sentences = set()  # 중복 제거를 위해 set 사용\n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = preprocess_sentence(sentence)  # 전처리 수행\n",
    "        tokenized = tokenizer(sentence)  # 형태소 분석기 사용\n",
    "\n",
    "        if len(tokenized) > max_len:\n",
    "            continue  # 최대 길이를 초과하는 문장은 제외\n",
    "\n",
    "        joined_sentence = \" \".join(tokenized)\n",
    "        if joined_sentence not in processed_sentences:  # 중복 제거\n",
    "            processed_sentences.add(joined_sentence)\n",
    "            tokenized_sentences.append(tokenized)\n",
    "\n",
    "    return tokenized_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12시', '땡', '!'], ['1', '지망', '학교', '떨어졌어'], ['3', '박', '4일', '놀러', '가고', '싶다'], ['3', '박', '4일', '정도', '놀러', '가고', '싶다'], ['ppl', '심하네']]\n",
      "[['하루', '가', '또', '가네요', '.'], ['위로', '해', '드립니다', '.'], ['여행', '은', '언제나', '좋죠', '.'], ['눈살', '이', '찌푸려지죠', '.'], ['다시', '새로', '사는', '게', '마음', '편해요', '.']]\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "que_corpus = build_corpus(questions, tokenizer)\n",
    "ans_corpus = build_corpus(answers, tokenizer)\n",
    "\n",
    "print(que_corpus[:5])\n",
    "print(ans_corpus[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "- Embedding을 활용한 Lexical Subsitution 구현\n",
    "- gensim 라이브러리에 사전 훈련된 Embedding 모델 불러와 사용\n",
    "- 대표적으로 사용되는 Embedding 모델인 `word2vec-google-news-300`은 용량이 너무 크기 때문에 적당한 사이즈 모델인 `glove-wiki-gigaword-300` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/downtown/miniconda3/envs/fucklms/lib/python3.8/site-packages (from gensim==3.8.3) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/downtown/miniconda3/envs/fucklms/lib/python3.8/site-packages (from gensim==3.8.3) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/downtown/miniconda3/envs/fucklms/lib/python3.8/site-packages (from gensim==3.8.3) (1.15.0)\n",
      "Collecting smart-open>=1.8.1 (from gensim==3.8.3)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /home/downtown/miniconda3/envs/fucklms/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim==3.8.3) (1.12.1)\n",
      "Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Gensim Word2Vec 모델 로드\n",
    "ko_model_path = \"/home/downtown/aiffel/transformer_chatbot/ko.bin\"\n",
    "\n",
    "wv = Word2Vec.load(ko_model_path)\n",
    "\n",
    "# 단어 벡터만 추출 (KeyedVectors 형태로 변환)\n",
    "wv = wv.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델에 포함된 단어 개수: 30185\n",
      "상위 10개 단어: ['관위', '정어리', '유식론', '장로회', '춘추관', '도입부', '민병', '어렵', '매니저', '청담']\n"
     ]
    }
   ],
   "source": [
    "if hasattr(wv, 'vocab'):\n",
    "    print(\"모델에 포함된 단어 개수:\", len(wv.vocab.keys()))\n",
    "    print(\"상위 10개 단어:\", list(wv.vocab.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def lexical_sub(sentence, wv, top_n=5, sub_prob=0.3):\n",
    "#     \"\"\"\n",
    "#     문장에서 랜덤한 단어 하나를 의미적으로 유사한 단어로 대체하여 데이터 증강 수행.\n",
    "    \n",
    "#     :param sentence: 원본 문장 (str)\n",
    "#     :param wv: GloVe 등 사전 학습된 단어 임베딩 모델\n",
    "#     :param top_n: 유사한 단어 후보 개수 (default: 5)\n",
    "#     :param sub_prob: 단어 치환 확률 (0~1, default: 0.3)\n",
    "#     :return: 치환된 문장 (원본과 동일하면 None 반환)\n",
    "#     \"\"\"\n",
    "#     words = sentence.split()\n",
    "    \n",
    "#     # 치환할 단어를 랜덤 선택 (확률 기반)\n",
    "#     if random.random() > sub_prob or not words:\n",
    "#         return None  # 치환 확률이 낮거나 문장이 비어있으면 변경하지 않음\n",
    "    \n",
    "#     selected_tok = random.choice(words)  # 랜덤하게 하나의 단어 선택\n",
    "    \n",
    "#     try:\n",
    "#         # 선택된 단어와 의미적으로 유사한 단어 중 하나 선택\n",
    "#         similar_words = [w for w, _ in wv.most_similar(selected_tok, topn=top_n)]\n",
    "#         new_word = random.choice(similar_words) if similar_words else selected_tok\n",
    "#     except KeyError:\n",
    "#         return None  # 선택된 단어가 Word2Vec 모델에 없으면 치환하지 않음\n",
    "\n",
    "#     # 선택된 단어를 유사한 단어로 치환\n",
    "#     new_sentence = \" \".join([new_word if tok == selected_tok else tok for tok in words])\n",
    "    \n",
    "#     return new_sentence if new_sentence != sentence else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 7748/11644 [00:06<00:03, 1112.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# aug_que_corpus = []  # 질문 데이터 증강\n",
    "# aug_ans_corpus = []  # 답변 데이터 증강\n",
    "\n",
    "# for src, tgt in tqdm(zip(que_corpus, ans_corpus), total=len(que_corpus)):\n",
    "#     # 질문(que_corpus)만 Augmentation하고 답변(ans_corpus)은 원본 유지\n",
    "#     new_src = lexical_sub(\" \".join(src), wv)  # 원본은 토큰 리스트이므로 문자열로 변환\n",
    "#     if new_src is not None:\n",
    "#         aug_que_corpus.append(new_src.split())  # Augmentation된 문장 추가\n",
    "#         aug_ans_corpus.append(tgt)  # 원본 답변 유지\n",
    "    \n",
    "#     # 답변(ans_corpus)만 Augmentation하고 질문(que_corpus)은 원본 유지\n",
    "#     new_tgt = lexical_sub(\" \".join(tgt), wv)\n",
    "#     if new_tgt is not None:\n",
    "#         aug_que_corpus.append(src)  # 원본 질문 유지\n",
    "#         aug_ans_corpus.append(new_tgt.split())  # Augmentation된 문장 추가\n",
    "    \n",
    "#     # 원본 데이터도 포함\n",
    "#     aug_que_corpus.append(src)\n",
    "#     aug_ans_corpus.append(tgt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "증강을 하다 말고 맘대로 끝낸다 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터 크기: 원본 11644 → 증강 후 10737\n",
      "aug_que\n",
      "[['12시', '땡', '!'], ['1', '지망', '강습소', '떨어졌어'], ['1', '지망', '학교', '떨어졌어'], ['3', '박', '4일', '놀러', '가고', '싶다'], ['3', '박', '4일', '정도', '놀러', '가고', '싶다']]\n",
      "aug_ans\n",
      "[['하루', '가', '또', '가네요', '.'], ['위로', '해', '드립니다', '.'], ['위로', '해', '드립니다', '.'], ['여행', '은', '언제나', '좋죠', '.'], ['눈살', '이', '찌푸려지죠', '.']]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"\\n데이터 크기: 원본 {len(que_corpus)} → 증강 후 {len(aug_que_corpus)}\")\n",
    "\n",
    "# print(\"aug_que\")\n",
    "# print(aug_que_corpus[:5])\n",
    "\n",
    "# print(\"aug_ans\")\n",
    "# print(aug_ans_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오히려 증강 후 수가 더 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lexical_sub(sentence, wv, top_n=5, sub_prob=0.3):\n",
    "#     words = sentence.split()\n",
    "    \n",
    "#     # 치환할 단어를 랜덤 선택 (확률 기반)\n",
    "#     if random.random() > sub_prob or not words:\n",
    "#         return None\n",
    "    \n",
    "#     selected_tok = random.choice(words)  # 랜덤하게 하나의 단어 선택\n",
    "    \n",
    "#     try:\n",
    "#         # 선택된 단어와 의미적으로 유사한 단어 중 하나 선택\n",
    "#         similar_words = [w for w, _ in wv.most_similar(selected_tok, topn=top_n)]\n",
    "#         new_word = random.choice(similar_words) if similar_words else selected_tok\n",
    "#     except (KeyError, ValueError, IndexError):\n",
    "#         return None  # 단어가 모델에 없거나 유사 단어가 없을 경우 무시\n",
    "\n",
    "#     new_sentence = \" \".join([new_word if tok == selected_tok else tok for tok in words])\n",
    "#     return new_sentence if new_sentence != sentence else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 7748/11644 [00:19<00:09, 396.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# aug_que_corpus = []\n",
    "# aug_ans_corpus = []\n",
    "\n",
    "# sub_prob = 0.7  # 70% 확률로 단어 교체\n",
    "\n",
    "# for src, tgt in tqdm(zip(que_corpus, ans_corpus), total=len(que_corpus), leave=True):\n",
    "#     new_src = lexical_sub(\" \".join(src), wv, sub_prob=sub_prob)  # sub_prob 적용\n",
    "#     new_tgt = lexical_sub(\" \".join(tgt), wv, sub_prob=sub_prob)\n",
    "\n",
    "#     if new_src is not None:\n",
    "#         aug_que_corpus.append(new_src.split())\n",
    "#         aug_ans_corpus.append(tgt)\n",
    "\n",
    "#     if new_tgt is not None:\n",
    "#         aug_que_corpus.append(src)\n",
    "#         aug_ans_corpus.append(new_tgt.split())\n",
    "\n",
    "#     aug_que_corpus.append(src)\n",
    "#     aug_ans_corpus.append(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터 크기: 원본 11644 → 증강 후 14665\n",
      "aug_que\n",
      "[['12시', '땡', '크레딧'], ['12시', '땡', '!'], ['1', '지망', '중고등학교', '떨어졌어'], ['1', '지망', '학교', '떨어졌어'], ['3', '박', '4일', '놀러', '가고', '싶다']]\n",
      "aug_ans\n",
      "[['하루', '가', '또', '가네요', '.'], ['하루', '가', '또', '가네요', '.'], ['위로', '해', '드립니다', '.'], ['위로', '해', '드립니다', '.'], ['여행', '이란', '언제나', '좋죠', '.']]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"\\n데이터 크기: 원본 {len(que_corpus)} → 증강 후 {len(aug_que_corpus)}\")\n",
    "\n",
    "# print(\"aug_que\")\n",
    "# print(aug_que_corpus[:5])\n",
    "\n",
    "# print(\"aug_ans\")\n",
    "# print(aug_ans_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터에서 None 발생 개수: 9437\n",
      "답변 데이터에서 None 발생 개수: 6623\n"
     ]
    }
   ],
   "source": [
    "none_count_enc = 0\n",
    "none_count_dec = 0\n",
    "\n",
    "# 질문 데이터에서 None 발생 개수 확인\n",
    "for src in que_corpus:\n",
    "    if lexical_sub(\" \".join(src), wv) is None:\n",
    "        none_count_enc += 1\n",
    "\n",
    "# 답변 데이터에서 None 발생 개수 확인\n",
    "for tgt in ans_corpus:\n",
    "    if lexical_sub(\" \".join(tgt), wv) is None:\n",
    "        none_count_dec += 1\n",
    "\n",
    "print(f\"질문 데이터에서 None 발생 개수: {none_count_enc}\")\n",
    "print(f\"답변 데이터에서 None 발생 개수: {none_count_dec}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 증강 코드를 보면 OOV 일 경우 None을 반환하는데 원본 문장을 반환하도록 증강 코드 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, wv, top_n=5, sub_prob=0.3):\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # 치환할 단어를 랜덤 선택 (확률 기반)\n",
    "    if random.random() > sub_prob or not words:\n",
    "        return None\n",
    "    \n",
    "    selected_tok = random.choice(words)  # 랜덤하게 하나의 단어 선택\n",
    "    \n",
    "    try:\n",
    "        # 선택된 단어와 의미적으로 유사한 단어 중 하나 선택\n",
    "        similar_words = [w for w, _ in wv.most_similar(selected_tok, topn=top_n)]\n",
    "        new_word = random.choice(similar_words) if similar_words else selected_tok\n",
    "    except (KeyError, ValueError, IndexError):\n",
    "        return sentence  # 단어가 모델에 없거나 유사 단어가 없을 경우 원본 문장 반환환\n",
    "\n",
    "    new_sentence = \" \".join([new_word if tok == selected_tok else tok for tok in words])\n",
    "    return new_sentence if new_sentence != sentence else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372fa5e5f1c14685ab4f765b7c466f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aug_que_corpus = []\n",
    "aug_ans_corpus = []\n",
    "\n",
    "sub_prob = 0.7  # 70% 확률로 단어 교체\n",
    "\n",
    "for src, tgt in tqdm(zip(que_corpus, ans_corpus), total=len(que_corpus), leave=True):\n",
    "    new_src = lexical_sub(\" \".join(src), wv, sub_prob=sub_prob)  # sub_prob 적용\n",
    "    new_tgt = lexical_sub(\" \".join(tgt), wv, sub_prob=sub_prob)\n",
    "\n",
    "    if new_src is not None:\n",
    "        aug_que_corpus.append(new_src.split())\n",
    "        aug_ans_corpus.append(tgt)\n",
    "\n",
    "    if new_tgt is not None:\n",
    "        aug_que_corpus.append(src)\n",
    "        aug_ans_corpus.append(new_tgt.split())\n",
    "\n",
    "    aug_que_corpus.append(src)\n",
    "    aug_ans_corpus.append(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터 크기: 원본 11644 → 증강 후 18732\n",
      "aug_que\n",
      "[['12시', 'ㅋ', '!'], ['12시', '땡', '!'], ['12시', '땡', '!'], ['1', '지망', '전문학교', '떨어졌어'], ['1', '지망', '학교', '떨어졌어']]\n",
      "aug_ans\n",
      "[['하루', '가', '또', '가네요', '.'], ['하루', '가', '또', '가네요', '.'], ['하루', '가', '또', '가네요', '.'], ['위로', '해', '드립니다', '.'], ['꿇', '해', '드립니다', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n데이터 크기: 원본 {len(que_corpus)} → 증강 후 {len(aug_que_corpus)}\")\n",
    "\n",
    "print(\"aug_que\")\n",
    "print(aug_que_corpus[:5])\n",
    "\n",
    "print(\"aug_ans\")\n",
    "print(aug_ans_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟 데이터인 ans_corpus 에 \\<start\\> 토큰과 \\<end\\> 토큰 추가 후 벡터화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ans_corpus = [[\"<start>\"] + ans + [\"<end>\"] for ans in aug_ans_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<start>', '하루', '가', '또', '가네요', '.', '<end>'], ['<start>', '하루', '가', '또', '가네요', '.', '<end>'], ['<start>', '하루', '가', '또', '가네요', '.', '<end>']]\n"
     ]
    }
   ],
   "source": [
    "print(aug_ans_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 사전 크기: 12559\n",
      "샘플 단어 10개: ['<pad>', '<unk>', '!', '!!', '!!!', '!?', ',', ',,', ',.', '.']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 전체 데이터 통합\n",
    "all_sentences = aug_que_corpus + aug_ans_corpus  # 질문 + 답변 데이터 결합\n",
    "\n",
    "# 단어 사전 생성\n",
    "word_counts = Counter(token for sentence in all_sentences for token in sentence)\n",
    "vocab = [\"<pad>\", \"<unk>\"] + sorted(word_counts.keys())  # <pad>, <unk> 추가\n",
    "\n",
    "# 단어 → 인덱스 매핑\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "# 사전 크기 확인\n",
    "print(f\"단어 사전 크기: {len(vocab)}\")\n",
    "print(f\"샘플 단어 10개: {list(word2idx.keys())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_train 샘플 크기 : 18732\n",
      "dec_train 샘플 크기 : 18732\n",
      "인코더 입력 샘플 : [[27, 103, 2], [27, 3392, 2]]\n",
      "디코더 입력 샘플 : [[76, 11663, 109, 3474, 130, 9, 75], [76, 11663, 109, 3474, 130, 9, 75]]\n",
      "enc_train max len : 17\n",
      "dec_train max len : 33\n"
     ]
    }
   ],
   "source": [
    "## 단어를 벡터화하여 모델 입력 데이터로 변환\n",
    "\n",
    "# 문장을 인덱스 벡터로 변환하는 함수\n",
    "def tokenize(sentences, word2idx):\n",
    "    return [[word2idx.get(token, word2idx[\"<unk>\"]) for token in sentence] for sentence in sentences]\n",
    "\n",
    "# 질문과 답변 데이터를 인덱스로 변환\n",
    "enc_train = tokenize(aug_que_corpus, word2idx)  # 인코더 입력\n",
    "dec_train = tokenize(aug_ans_corpus, word2idx)  # 디코더 입력\n",
    "\n",
    "# 데이터 크기 확인\n",
    "print(f\"enc_train 샘플 크기 : {len(enc_train)}\")\n",
    "print(f\"dec_train 샘플 크기 : {len(dec_train)}\")\n",
    "\n",
    "# 샘플 확인\n",
    "print(\"인코더 입력 샘플 :\", enc_train[:2])\n",
    "print(\"디코더 입력 샘플 :\", dec_train[:2])\n",
    "\n",
    "# 각 데이터셋의 최대 길이 확인\n",
    "enc_max_len = max(len(seq) for seq in enc_train)\n",
    "dec_max_len = max(len(seq) for seq in dec_train)\n",
    "\n",
    "# 최대 길이 확인\n",
    "print(f\"enc_train max len : {enc_max_len}\")\n",
    "print(f\"dec_train max len : {dec_max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 문장의 토큰 길이가 각각의 max len이 되도록 설정\n",
    "enc_ndarray = tf.keras.preprocessing.sequence.pad_sequences(enc_train, maxlen=enc_max_len, padding='post')\n",
    "dec_ndarray = tf.keras.preprocessing.sequence.pad_sequences(dec_train, maxlen=dec_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 01:15:04.014603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-13 01:15:04.061222: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# 훈련에 사용할 수 있도록 각 데이터를 묶어 배치 크기의 텐서로 만들어 줌\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_ndarray, dec_ndarray)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트랜스포머 구현\n",
    "Encoder와 Decoder 각각의 Embedding과 출력층의 Linear, 총 3개의 레이어가 Weight를 공유할 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding 구현\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask  생성하기\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head Attention 구현\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Position-wise Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network 구현\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder의 레이어 구현\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 레이어 구현\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 구현\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 구현\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformer 전체 모델 조립"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 하이퍼파라미터로 Transformer 인스턴스 생성\n",
    "transformer = Transformer(\n",
    "    n_layers=3,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=len(vocab),\n",
    "    tgt_vocab_size=len(vocab),\n",
    "    pos_len=200,\n",
    "    dropout=0.2,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\t\t\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler 구현\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    WARMUP_STEPS = 3000\n",
    "    def __init__(self, d_model, warmup_steps=WARMUP_STEPS):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.pow(step, -0.5)\n",
    "        arg2 = step * tf.math.pow(self.warmup_steps, -1.5)\n",
    "        \n",
    "        return tf.math.pow(self.d_model, -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate 인스턴스 선언 & Optimizer 구현\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 정의\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상헌님 꿀팁 : 저 방금 훈련 돌려봤는데 레이어 개수 3개로 늘리니까 training loss가 훨씬 잘 떨어집니다 validation loss는 안 찍어봤는데 일단 훈련데이터에 대해선 확실히 효과있었습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1차 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8f9bc6156c4f9da355090e00b93478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 평균 손실: 6.6297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbc2c6848d64bc2a963a68212aaff03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 평균 손실: 5.0305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1f499fc1164411a44455171cf4ea1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 평균 손실: 4.2132\n"
     ]
    }
   ],
   "source": [
    "# Q. 위의 코드를 활용하여 모델을 훈련시켜봅시다!\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch, (src, tgt) in enumerate(train_dataset):\n",
    "        loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += loss\n",
    "        tqdm_bar.set_description(f\"Epoch {epoch+1} Loss: {loss.numpy():.4f}\")\n",
    "        tqdm_bar.update(1)\n",
    "    \n",
    "    tqdm_bar.close()\n",
    "    print(f\"Epoch {epoch+1} 평균 손실: {(total_loss / dataset_count):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 응답 생성 함수 (greedy decoding)\n",
    "def chat_response(sentence, model, word2idx, idx2word, max_len_enc, max_len_dec):\n",
    "    # 입력이 리스트라면 문자열로 변환\n",
    "    if isinstance(sentence, list):\n",
    "        sentence = \" \".join(sentence)\n",
    "\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    # 간단한 토큰화 (이미 전처리된 문장은 공백 기준 분리)\n",
    "    tokens = sentence.split()\n",
    "    # 단어를 인덱스로 변환 (없으면 <unk>로 처리)\n",
    "    input_ids = [word2idx.get(token, word2idx[\"<unk>\"]) for token in tokens]\n",
    "    # 인코더 입력 벡터로 패딩 (배치 크기 1)\n",
    "    input_ids = tf.keras.preprocessing.sequence.pad_sequences([input_ids], maxlen=max_len_enc, padding='post')\n",
    "    encoder_input = tf.convert_to_tensor(input_ids)\n",
    "    \n",
    "    # 디코더 입력 초기화 (<start> 토큰)\n",
    "    decoder_input = [word2idx[\"<start>\"]]\n",
    "    \n",
    "    for i in range(max_len_dec):\n",
    "        # 현재 디코더 입력을 max_len_dec에 맞춰 패딩\n",
    "        dec_input_padded = tf.keras.preprocessing.sequence.pad_sequences([decoder_input], maxlen=max_len_dec, padding='post')\n",
    "        dec_input_tensor = tf.convert_to_tensor(dec_input_padded)\n",
    "        \n",
    "        # 마스크 생성 (generate_masks 함수가 이미 정의되어 있다고 가정)\n",
    "        enc_mask, combined_mask, dec_mask = generate_masks(encoder_input, dec_input_tensor)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        predictions, _, _, _ = model(encoder_input, dec_input_tensor, enc_mask, combined_mask, dec_mask)\n",
    "        # predictions shape: (batch, sequence_length, vocab_size)\n",
    "        # 현재 단계: decoder_input의 길이 - 1 (마지막 토큰의 위치)\n",
    "        predicted_id = tf.argmax(predictions[0, len(decoder_input)-1]).numpy()\n",
    "        \n",
    "        # <end> 토큰이면 종료\n",
    "        if predicted_id == word2idx[\"<end>\"]:\n",
    "            break\n",
    "        \n",
    "        # 예측된 토큰을 디코더 입력에 추가\n",
    "        decoder_input.append(predicted_id)\n",
    "    \n",
    "    # 디코더 입력 중, 첫 번째 <start> 토큰 제외하고 단어로 변환\n",
    "    response_tokens = [idx2word[idx] for idx in decoder_input[1:]]\n",
    "    return \" \".join(response_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translations\n",
      "> 1. 정말 사랑 하는 것 도 좋을 것 같아요 . <end>\n",
      "> 2. 사랑 은 사랑 은 언제나 하는 거 예요 . <end>\n",
      "> 3. 사랑 은 나 봐요 . <end>\n",
      "> 4. 정말 사랑 하는 것 도 좋을 것 같아요 . <end>\n",
      "\n",
      "Hyperparameters\n",
      "> n_layers: 2\n",
      "> d_model: 512.0\n",
      "> n_heads: 8\n",
      "> d_ff: 2048\n",
      "> dropout: 0.3\n",
      "\n",
      "Training Parameters\n",
      "> Warmup Steps: 4000\n",
      "> Batch Size: 64\n",
      "> Epoch At: 3\n"
     ]
    }
   ],
   "source": [
    "# 인코더, 디코더의 최대 길이\n",
    "enc_max_len = enc_ndarray.shape[1]\n",
    "dec_max_len = dec_ndarray.shape[1]\n",
    "\n",
    "# 테스트용 예문\n",
    "test_queries = [\n",
    "    \"지루하다, 놀러가고 싶어.\",\n",
    "    \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "    \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "    \"집에 있는다는 소리야.\"\n",
    "]\n",
    "\n",
    "# 챗봇 응답 생성\n",
    "responses = [chat_response(query, transformer, word2idx, idx2word, enc_max_len, dec_max_len) \n",
    "             for query in test_queries]\n",
    "\n",
    "# 제출 형식에 맞게 결과 출력\n",
    "print(\"\\nTranslations\")\n",
    "for i, response in enumerate(responses, 1):\n",
    "    print(f\"> {i}. {response} <end>\")\n",
    "\n",
    "# 하이퍼파라미터 출력 함수\n",
    "def print_hyperparameters(model):\n",
    "    print(\"\\nHyperparameters\")\n",
    "    print(\"> n_layers:\", model.n_layers)\n",
    "    print(\"> d_model:\", model.d_model.numpy() if hasattr(model.d_model, \"numpy\") else model.d_model)\n",
    "    print(\"> n_heads:\", model.n_heads)\n",
    "    print(\"> d_ff:\", model.d_ff)\n",
    "    print(\"> dropout:\", model.do.rate)\n",
    "\n",
    "print_hyperparameters(transformer)\n",
    "\n",
    "# 훈련 파라미터 (학습 시 사용한 값)\n",
    "\n",
    "print(\"\\nTraining Parameters\")\n",
    "print(\"> Warmup Steps:\", LearningRateScheduler.WARMUP_STEPS)\n",
    "print(\"> Batch Size:\", BATCH_SIZE)\n",
    "print(\"> Epoch At:\", EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_bleu_single(model, src_sentence, tgt_sentence, word2idx, idx2word, max_len_enc, max_len_dec, verbose=True):\n",
    "    # 만약 src_sentence나 tgt_sentence가 리스트라면 문자열로 변환\n",
    "    if isinstance(src_sentence, list):\n",
    "        src_str = \" \".join(src_sentence)\n",
    "    else:\n",
    "        src_str = src_sentence\n",
    "    if isinstance(tgt_sentence, list):\n",
    "        tgt_str = \" \".join(tgt_sentence)\n",
    "    else:\n",
    "        tgt_str = tgt_sentence\n",
    "\n",
    "    candidate = chat_response(src_str, model, word2idx, idx2word, max_len_enc, max_len_dec)\n",
    "    candidate_tokens = candidate.split()\n",
    "    reference_tokens = tgt_str.split()\n",
    "\n",
    "    score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=SmoothingFunction().method1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Source Sentence: \", src_str)\n",
    "        print(\"Model Prediction: \", candidate)\n",
    "        print(\"Reference: \", tgt_str)\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score\n",
    "\n",
    "def eval_bleu(model, src_sentences, tgt_sentences, word2idx, idx2word, max_len_enc, max_len_dec, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in tqdm(range(sample_size), desc=\"Evaluating\"):\n",
    "        score = eval_bleu_single(model, src_sentences[idx], tgt_sentences[idx],\n",
    "                                 word2idx, idx2word, max_len_enc, max_len_dec, verbose)\n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Samples:\", sample_size)\n",
    "    print(\"Average BLEU Score: {:.4f}\".format(total_score / sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu_batch(queries, references, model, word2idx, idx2word, max_len_enc, max_len_dec, eval_batch_size=64):\n",
    "    \"\"\"\n",
    "    전체 데이터셋(queries, references)을 배치 처리하여 BLEU Score를 계산하는 함수.\n",
    "    queries, references는 문자열 리스트.\n",
    "    \"\"\"\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    # 배치로 챗봇 응답 생성\n",
    "    responses = chat_response_batch(queries, model, word2idx, idx2word, max_len_enc, max_len_dec, eval_batch_size)\n",
    "    \n",
    "    bleu_scores = []\n",
    "    for resp, ref in zip(responses, references):\n",
    "        candidate_tokens = resp.split()\n",
    "        reference_tokens = ref.split()  # reference가 문자열로 되어 있다고 가정\n",
    "        score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smooth_fn)\n",
    "        bleu_scores.append(score)\n",
    "        \n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "    return avg_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_bleu(transformer, que_corpus, ans_corpus, word2idx, idx2word, enc_max_len, dec_max_len, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bleu score 용 sample data 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출 완료: 2000개\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# 무작위로 2000개 샘플 추출\n",
    "def sample_random_data(que_corpus, ans_corpus, sample_size=2000):\n",
    "    \"\"\"\n",
    "    전체 토큰화된 질문(que_corpus)과 정답(ans_corpus)에서 무작위로 sample_size개 샘플을 추출합니다.\n",
    "    \n",
    "    que_corpus, ans_corpus: 토큰화된 문장 리스트들 (예: [['12시', '땡', '!'], ...])\n",
    "    sample_size: 추출할 샘플 수 (기본 2000)\n",
    "    \n",
    "    Returns:\n",
    "      sampled_questions: 선택된 질문(토큰 리스트)\n",
    "      sampled_answers: 선택된 정답(토큰 리스트)\n",
    "    \"\"\"\n",
    "    total_samples = min(len(que_corpus), len(ans_corpus))\n",
    "    sample_size = sample_size if total_samples >= sample_size else total_samples\n",
    "    sample_indices = random.sample(range(total_samples), sample_size)\n",
    "    \n",
    "    sampled_questions = [que_corpus[i] for i in sample_indices]\n",
    "    sampled_answers   = [ans_corpus[i] for i in sample_indices]\n",
    "    return sampled_questions, sampled_answers\n",
    "\n",
    "# 샘플 데이터 추출\n",
    "sampled_questions, sampled_answers = sample_random_data(que_corpus, ans_corpus, sample_size=2000)\n",
    "print(\"샘플 추출 완료: {}개\".format(len(sampled_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab806904fd7b4f0e8588e7f4507cb5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating responses:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe42e40b2f44c3ead0b00b06ef77951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing BLEU scores:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample Average BLEU Score: 0.0373\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델로 샘플 질문에 대해 응답 생성 (chat_response 함수 사용)\n",
    "# chat_response 함수는 입력 문자열을 받아 챗봇 응답(문자열)을 반환\n",
    "generated_responses = []\n",
    "for question in tqdm(sampled_questions, desc=\"Generating responses\"):\n",
    "    # 질문은 토큰 리스트이므로 문자열로 변환\n",
    "    question_str = \" \".join(question)\n",
    "    response_str = chat_response(question_str, transformer, word2idx, idx2word, enc_max_len, dec_max_len)\n",
    "    generated_responses.append(response_str)\n",
    "\n",
    "# BLEU Score 계산\n",
    "smooth_fn = SmoothingFunction().method1\n",
    "bleu_scores = []\n",
    "# 샘플 정답(sampled_answers)은 토큰 리스트 그대로 사용, 모델 응답은 문자열이므로 split() 처리\n",
    "for ref_tokens, candidate_str in tqdm(zip(sampled_answers, generated_responses),\n",
    "                                       total=len(generated_responses),\n",
    "                                       desc=\"Computing BLEU scores\"):\n",
    "    candidate_tokens = candidate_str.split()\n",
    "    score = sentence_bleu([ref_tokens], candidate_tokens, smoothing_function=smooth_fn)\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "print(\"Random sample Average BLEU Score: {:.4f}\".format(avg_bleu))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2차 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e301a8dbd53848dcae5c6627d6d9f3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 평균 손실: 6.0877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904086a970ac494c9cd6c222ea0187ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 평균 손실: 4.7899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4a20df42ec44748d433d8a07405b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 평균 손실: 3.7832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b304bcfbe0d94af7a689c994e5a5e419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 평균 손실: 2.7715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11afc909aaa4a26b7bf8fb5639f9e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 평균 손실: 2.2006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac1c409725f4cb8957a2de2f4a4fb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 평균 손실: 1.9130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227dad5964de4062b93ab3084ba4b5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 평균 손실: 1.7117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c275ce47001441478bf3ed7267e6398b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 평균 손실: 1.5724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abaddcf97c54f30a355a8e3d4cd4eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 평균 손실: 1.5129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53104471394342979fca33ff1d167823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 평균 손실: 1.4586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ed7b28ef7e4a36b7734452164c6c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 평균 손실: 1.4366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707711a9d89d4f93b00843c126fef5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 평균 손실: 1.2623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960ac571996144a98d7d0ccc61c0d64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 평균 손실: 1.0582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99454ab39b024827ad3efb9a32b085e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 평균 손실: 0.9400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2005c584b3e497096b2a320cbc6342f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 평균 손실: 0.8237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6845a8c63c4247888bad2fe5ca5048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 평균 손실: 0.7295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77ab649547d40c38ee00a73a8e4688a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 평균 손실: 0.6754\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f0df6af9f847e9a7c4496bf06f31d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 평균 손실: 0.6113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0fb7eb308846a09cdabccb07c11593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 평균 손실: 0.5563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8434a3f73f64368985084ce91181d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 평균 손실: 0.5299\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q. 위의 코드를 활용하여 모델을 훈련시켜봅시다!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch, (src, tgt) in enumerate(train_dataset):\n",
    "        loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += loss\n",
    "        tqdm_bar.set_description(f\"Epoch {epoch+1} Loss: {loss.numpy():.4f}\")\n",
    "        tqdm_bar.update(1)\n",
    "    \n",
    "    tqdm_bar.close()\n",
    "    avg_loss = total_loss / dataset_count\n",
    "    epoch_losses.append(avg_loss.numpy())\n",
    "    print(f\"Epoch {epoch+1} 평균 손실: {avg_loss:.4f}\")\n",
    "\n",
    "# 에폭별 평균 손실 그래프 그리기\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, EPOCHS+1), epoch_losses, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 응답 생성 함수 (greedy decoding)\n",
    "def chat_response(sentence, model, word2idx, idx2word, max_len_enc, max_len_dec):\n",
    "    # 입력이 리스트라면 문자열로 변환\n",
    "    if isinstance(sentence, list):\n",
    "        sentence = \" \".join(sentence)\n",
    "\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    # 간단한 토큰화 (이미 전처리된 문장은 공백 기준 분리)\n",
    "    tokens = sentence.split()\n",
    "    # 단어를 인덱스로 변환 (없으면 <unk>로 처리)\n",
    "    input_ids = [word2idx.get(token, word2idx[\"<unk>\"]) for token in tokens]\n",
    "    # 인코더 입력 벡터로 패딩 (배치 크기 1)\n",
    "    input_ids = tf.keras.preprocessing.sequence.pad_sequences([input_ids], maxlen=max_len_enc, padding='post')\n",
    "    encoder_input = tf.convert_to_tensor(input_ids)\n",
    "    \n",
    "    # 디코더 입력 초기화 (<start> 토큰)\n",
    "    decoder_input = [word2idx[\"<start>\"]]\n",
    "    \n",
    "    for i in range(max_len_dec):\n",
    "        # 현재 디코더 입력을 max_len_dec에 맞춰 패딩\n",
    "        dec_input_padded = tf.keras.preprocessing.sequence.pad_sequences([decoder_input], maxlen=max_len_dec, padding='post')\n",
    "        dec_input_tensor = tf.convert_to_tensor(dec_input_padded)\n",
    "        \n",
    "        # 마스크 생성 (generate_masks 함수가 이미 정의되어 있다고 가정)\n",
    "        enc_mask, combined_mask, dec_mask = generate_masks(encoder_input, dec_input_tensor)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        predictions, _, _, _ = model(encoder_input, dec_input_tensor, enc_mask, combined_mask, dec_mask)\n",
    "        # predictions shape: (batch, sequence_length, vocab_size)\n",
    "        # 현재 단계: decoder_input의 길이 - 1 (마지막 토큰의 위치)\n",
    "        predicted_id = tf.argmax(predictions[0, len(decoder_input)-1]).numpy()\n",
    "        \n",
    "        # <end> 토큰이면 종료\n",
    "        if predicted_id == word2idx[\"<end>\"]:\n",
    "            break\n",
    "        \n",
    "        # 예측된 토큰을 디코더 입력에 추가\n",
    "        decoder_input.append(predicted_id)\n",
    "    \n",
    "    # 디코더 입력 중, 첫 번째 <start> 토큰 제외하고 단어로 변환\n",
    "    response_tokens = [idx2word[idx] for idx in decoder_input[1:]]\n",
    "    return \" \".join(response_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translations\n",
      "> 1. 그게 무슨 부분 으로 착각 만 할 수 있어요 . <end>\n",
      "> 2. 마음 이 것 건지 바쁜 까지 해보세요 . <end>\n",
      "> 3. 그게 무슨 부분 이에요 . <end>\n",
      "> 4. 그게 무슨 부분 으로 착각 만 할 수 있어요 . <end>\n",
      "\n",
      "Hyperparameters\n",
      "> n_layers: 3\n",
      "> d_model: 512.0\n",
      "> n_heads: 8\n",
      "> d_ff: 2048\n",
      "> dropout: 0.2\n",
      "\n",
      "Training Parameters\n",
      "> Warmup Steps: 3000\n",
      "> Batch Size: 64\n",
      "> Epoch At: 20\n"
     ]
    }
   ],
   "source": [
    "# 인코더, 디코더의 최대 길이\n",
    "enc_max_len = enc_ndarray.shape[1]\n",
    "dec_max_len = dec_ndarray.shape[1]\n",
    "\n",
    "# 테스트용 예문\n",
    "test_queries = [\n",
    "    \"지루하다, 놀러가고 싶어.\",\n",
    "    \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "    \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "    \"집에 있는다는 소리야.\"\n",
    "]\n",
    "\n",
    "# 챗봇 응답 생성\n",
    "responses = [chat_response(query, transformer, word2idx, idx2word, enc_max_len, dec_max_len) \n",
    "             for query in test_queries]\n",
    "\n",
    "# 제출 형식에 맞게 결과 출력\n",
    "print(\"\\nTranslations\")\n",
    "for i, response in enumerate(responses, 1):\n",
    "    print(f\"> {i}. {response} <end>\")\n",
    "\n",
    "# 하이퍼파라미터 출력 함수\n",
    "def print_hyperparameters(model):\n",
    "    print(\"\\nHyperparameters\")\n",
    "    print(\"> n_layers:\", model.n_layers)\n",
    "    print(\"> d_model:\", model.d_model.numpy() if hasattr(model.d_model, \"numpy\") else model.d_model)\n",
    "    print(\"> n_heads:\", model.n_heads)\n",
    "    print(\"> d_ff:\", model.d_ff)\n",
    "    print(\"> dropout:\", model.do.rate)\n",
    "\n",
    "print_hyperparameters(transformer)\n",
    "\n",
    "# 훈련 파라미터 (학습 시 사용한 값)\n",
    "\n",
    "print(\"\\nTraining Parameters\")\n",
    "print(\"> Warmup Steps:\", LearningRateScheduler.WARMUP_STEPS)\n",
    "print(\"> Batch Size:\", BATCH_SIZE)\n",
    "print(\"> Epoch At:\", EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출 완료: 2000개\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# 무작위로 2000개 샘플 추출\n",
    "def sample_random_data(que_corpus, ans_corpus, sample_size=2000):\n",
    "    \"\"\"\n",
    "    전체 토큰화된 질문(que_corpus)과 정답(ans_corpus)에서 무작위로 sample_size개 샘플을 추출합니다.\n",
    "    \n",
    "    que_corpus, ans_corpus: 토큰화된 문장 리스트들 (예: [['12시', '땡', '!'], ...])\n",
    "    sample_size: 추출할 샘플 수 (기본 2000)\n",
    "    \n",
    "    Returns:\n",
    "      sampled_questions: 선택된 질문(토큰 리스트)\n",
    "      sampled_answers: 선택된 정답(토큰 리스트)\n",
    "    \"\"\"\n",
    "    total_samples = min(len(que_corpus), len(ans_corpus))\n",
    "    sample_size = sample_size if total_samples >= sample_size else total_samples\n",
    "    sample_indices = random.sample(range(total_samples), sample_size)\n",
    "    \n",
    "    sampled_questions = [que_corpus[i] for i in sample_indices]\n",
    "    sampled_answers   = [ans_corpus[i] for i in sample_indices]\n",
    "    return sampled_questions, sampled_answers\n",
    "\n",
    "# 샘플 데이터 추출\n",
    "sampled_questions, sampled_answers = sample_random_data(que_corpus, ans_corpus, sample_size=2000)\n",
    "print(\"샘플 추출 완료: {}개\".format(len(sampled_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfb666c5a9540dba508cd959ee1ff52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating responses:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885e414c6c047e396420e36d3ea7383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing BLEU scores:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample Average BLEU Score: 0.5826\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델로 샘플 질문에 대해 응답 생성 (chat_response 함수 사용)\n",
    "# chat_response 함수는 입력 문자열을 받아 챗봇 응답(문자열)을 반환\n",
    "generated_responses = []\n",
    "for question in tqdm(sampled_questions, desc=\"Generating responses\"):\n",
    "    # 질문은 토큰 리스트이므로 문자열로 변환\n",
    "    question_str = \" \".join(question)\n",
    "    response_str = chat_response(question_str, transformer, word2idx, idx2word, enc_max_len, dec_max_len)\n",
    "    generated_responses.append(response_str)\n",
    "\n",
    "# BLEU Score 계산\n",
    "smooth_fn = SmoothingFunction().method1\n",
    "bleu_scores = []\n",
    "# 샘플 정답(sampled_answers)은 토큰 리스트 그대로 사용, 모델 응답은 문자열이므로 split() 처리\n",
    "for ref_tokens, candidate_str in tqdm(zip(sampled_answers, generated_responses),\n",
    "                                       total=len(generated_responses),\n",
    "                                       desc=\"Computing BLEU scores\"):\n",
    "    candidate_tokens = candidate_str.split()\n",
    "    score = sentence_bleu([ref_tokens], candidate_tokens, smoothing_function=smooth_fn)\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "print(\"Random sample Average BLEU Score: {:.4f}\".format(avg_bleu))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "일단 mecab 설치하는 부분에서 시간이 너무 오래걸렸다.   \n",
    "결국 설치도 못하고.. okt로 바꿨지만..   \n",
    "다른 사람들은 어떻게 설치하셨을지 궁금하다.   \n",
    "그리고 BLEU score 계산할 때도 엄청 걸리던데 다른 분들은 어떻게 하셨는지 궁금하다.   \n",
    "난 결국 2000개 랜덤으로 추출해서 점수를 계산하는 방법을 선택했다.   \n",
    "그리고 원래 이렇게 오래 걸리는 지 궁금하다.  \n",
    "생각보다 시간이 너무 오래 걸려서 많은 실험을 하지는 못했지만 두 번째 실험 결과 BLEU score가 0.5를 넘겨서 너무 기분이 좋았다.   \n",
    "근데 예문 결과는 썩 별로라서... 뭔가 더 살펴봐야 될 것 같지만 이만 마무리하겠다...   \n",
    "그동안 했던 프로젝트 노드 중에서 거의 처음으로 성과를 확인할 수 있었던 노드라서 너무 기쁘다.   \n",
    "추후 좀 더 면밀하게 뜯어봐야겠다.   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fucklms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
