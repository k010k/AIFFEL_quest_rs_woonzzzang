{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6063fb",
   "metadata": {},
   "source": [
    "### 4-4. KoNLPy 감정 분석 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3351181",
   "metadata": {},
   "source": [
    "#### 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418bf7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                           document  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
      "        id                                           document  label\n",
      "0  6270596                                                굳 ㅋ      1\n",
      "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
      "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
      "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/naver_data/ratings_train.txt'\n",
    "test_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/naver_data/ratings_test.txt'\n",
    "\n",
    "# 데이터 불러오기\n",
    "train_data = pd.read_csv(train_file, sep='\\t')\n",
    "test_data = pd.read_csv(test_file, sep='\\t')\n",
    "\n",
    "# 데이터 확인\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ca19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 학습 데이터 개수: 146183\n",
      "전처리 후 테스트 데이터 개수: 49158\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "\n",
    "# 특수 문자 제거 (정규 표현식 사용)\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", regex=True)\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", regex=True)\n",
    "\n",
    "print(f\"전처리 후 학습 데이터 개수: {len(train_data)}\")\n",
    "print(f\"전처리 후 테스트 데이터 개수: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87575f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후 학습 데이터 개수: 145791\n",
      "필터링 후 테스트 데이터 개수: 48995\n"
     ]
    }
   ],
   "source": [
    "# 결측값(NaN) 제거\n",
    "train_data = train_data.dropna(subset=['document']).copy()\n",
    "test_data = test_data.dropna(subset=['document']).copy()\n",
    "\n",
    "# 문장 길이 필터링 (NaN 방지)\n",
    "filtered_train_data = train_data[train_data['document'].apply(lambda x: 1 <= len(str(x)) <= 140)].copy()\n",
    "filtered_test_data = test_data[test_data['document'].apply(lambda x: 1 <= len(str(x)) <= 140)].copy()\n",
    "\n",
    "print(f\"필터링 후 학습 데이터 개수: {len(filtered_train_data)}\")\n",
    "print(f\"필터링 후 테스트 데이터 개수: {len(filtered_test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0329bf7",
   "metadata": {},
   "source": [
    "#### Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599e9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy (Mecab) 토큰화 예시: ['아 더 빙 진짜 짜증 나 네요 목소리', '흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍 지 않 구나', '너무 재 밓었다그래서보는것을추천한다', '교도소 이야기 구먼 솔직히 재미 는 없 다 평점 조정', '사이몬페그 의 익살 스런 연기 가 돋보였 던 영화 스파이더맨 에서 늙 어 보이 기 만 했 던 커스틴 던스트 가 너무나 도 이뻐 보였 다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 형태소 분석기 변경\n",
    "tokenizer = Mecab()\n",
    "\n",
    "def tokenize_konlpy(corpus, tokenizer):\n",
    "    return [' '.join(tokenizer.morphs(sentence)) for sentence in corpus]\n",
    "\n",
    "# KoNLPy 기반 토큰화 적용 (Mecab 사용)\n",
    "train_corpus_konlpy = tokenize_konlpy(filtered_train_data['document'], tokenizer)\n",
    "test_corpus_konlpy = tokenize_konlpy(filtered_test_data['document'], tokenizer)\n",
    "\n",
    "print(\"KoNLPy (Mecab) 토큰화 예시:\", train_corpus_konlpy[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78181d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy 기반 변환된 훈련 데이터 크기: (145791, 95)\n",
      "KoNLPy 기반 변환된 테스트 데이터 크기: (48995, 93)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 토크나이저 정의\n",
    "konlpy_tokenizer = Tokenizer()\n",
    "konlpy_tokenizer.fit_on_texts(train_corpus_konlpy)\n",
    "\n",
    "# 정수 인코딩\n",
    "train_tensor_konlpy = konlpy_tokenizer.texts_to_sequences(train_corpus_konlpy)\n",
    "test_tensor_konlpy = konlpy_tokenizer.texts_to_sequences(test_corpus_konlpy)\n",
    "\n",
    "# 패딩 적용\n",
    "train_tensor_konlpy = pad_sequences(train_tensor_konlpy, padding='post')\n",
    "test_tensor_konlpy = pad_sequences(test_tensor_konlpy, padding='post')\n",
    "\n",
    "print(\"KoNLPy 기반 변환된 훈련 데이터 크기:\", train_tensor_konlpy.shape)\n",
    "print(\"KoNLPy 기반 변환된 테스트 데이터 크기:\", test_tensor_konlpy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69703f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2278/2278 [==============================] - 138s 58ms/step - loss: 0.3696 - accuracy: 0.8345 - val_loss: 0.3306 - val_accuracy: 0.8558\n",
      "Epoch 2/5\n",
      "2278/2278 [==============================] - 131s 57ms/step - loss: 0.2637 - accuracy: 0.8901 - val_loss: 0.3275 - val_accuracy: 0.8578\n",
      "Epoch 3/5\n",
      "2278/2278 [==============================] - 129s 56ms/step - loss: 0.2023 - accuracy: 0.9182 - val_loss: 0.3503 - val_accuracy: 0.8580\n",
      "Epoch 4/5\n",
      "2278/2278 [==============================] - 130s 57ms/step - loss: 0.1558 - accuracy: 0.9392 - val_loss: 0.3825 - val_accuracy: 0.8551\n",
      "Epoch 5/5\n",
      "2278/2278 [==============================] - 131s 58ms/step - loss: 0.1240 - accuracy: 0.9532 - val_loss: 0.4483 - val_accuracy: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7b9122ac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# 같은 모델 구조로 학습\n",
    "konlpy_model = Sequential([\n",
    "    Embedding(input_dim=len(konlpy_tokenizer.word_index) + 1, output_dim=128, mask_zero=True),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "konlpy_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 레이블 데이터 준비\n",
    "train_labels = filtered_train_data['label'].values\n",
    "test_labels = filtered_test_data['label'].values\n",
    "\n",
    "# 모델 학습\n",
    "konlpy_model.fit(train_tensor_konlpy, train_labels, \n",
    "                 validation_data=(test_tensor_konlpy, test_labels),\n",
    "                 epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f3a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.4483 - accuracy: 0.8516\n",
      "KoNLPy 기반 테스트 정확도: 0.8516\n"
     ]
    }
   ],
   "source": [
    "konlpy_test_loss, konlpy_test_acc = konlpy_model.evaluate(test_tensor_konlpy, test_labels)\n",
    "print(f\"KoNLPy 기반 테스트 정확도: {konlpy_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5551eb",
   "metadata": {},
   "source": [
    "#### SentencePiece VS Mecab\n",
    "테스트 정확도   \n",
    "0.8527 > 0.8516"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1158f",
   "metadata": {},
   "source": [
    "#### Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170f8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 값 및 빈 문자열 제거\n",
    "filtered_train_data = filtered_train_data.dropna(subset=['document'])\n",
    "filtered_test_data = filtered_test_data.dropna(subset=['document'])\n",
    "\n",
    "filtered_train_data = filtered_train_data[filtered_train_data['document'].str.strip() != '']\n",
    "filtered_test_data = filtered_test_data[filtered_test_data['document'].str.strip() != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c173eee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy (Komoran) 토큰화 예시: ['아 더빙 진짜 짜증 나 네요 목소리', '흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍 지 않 구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기 이 구먼 솔직히 재미 는 없 다 평점 조정', '사이몬페그의 익살 스럽 ㄴ 연기 가 돋보이 었 던 영화 스파이더맨 에서 늙 어 보이 기 만 하 았 던 커스틴 던스트 가 너무나 도 이뻐보였다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "# 형태소 분석기 변경 (Komoran)\n",
    "tokenizer = Komoran()\n",
    "\n",
    "def tokenize_konlpy(corpus, tokenizer):\n",
    "    return [' '.join(tokenizer.morphs(str(sentence))) for sentence in corpus]\n",
    "\n",
    "# 형태소 분석기 변경 (Komoran)\n",
    "from konlpy.tag import Komoran\n",
    "tokenizer = Komoran()\n",
    "\n",
    "# KoNLPy 기반 토큰화 적용 (Komoran 사용)\n",
    "train_corpus_konlpy = tokenize_konlpy(filtered_train_data['document'], tokenizer)\n",
    "test_corpus_konlpy = tokenize_konlpy(filtered_test_data['document'], tokenizer)\n",
    "\n",
    "print(\"KoNLPy (Komoran) 토큰화 예시:\", train_corpus_konlpy[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4107f757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoNLPy 기반 변환된 훈련 데이터 크기: (145393, 104)\n",
      "KoNLPy 기반 변환된 테스트 데이터 크기: (48852, 105)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 토크나이저 정의\n",
    "konlpy_tokenizer = Tokenizer()\n",
    "konlpy_tokenizer.fit_on_texts(train_corpus_konlpy)\n",
    "\n",
    "# 정수 인코딩\n",
    "train_tensor_konlpy = konlpy_tokenizer.texts_to_sequences(train_corpus_konlpy)\n",
    "test_tensor_konlpy = konlpy_tokenizer.texts_to_sequences(test_corpus_konlpy)\n",
    "\n",
    "# 패딩 적용\n",
    "train_tensor_konlpy = pad_sequences(train_tensor_konlpy, padding='post')\n",
    "test_tensor_konlpy = pad_sequences(test_tensor_konlpy, padding='post')\n",
    "\n",
    "print(\"KoNLPy 기반 변환된 훈련 데이터 크기:\", train_tensor_konlpy.shape)\n",
    "print(\"KoNLPy 기반 변환된 테스트 데이터 크기:\", test_tensor_konlpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52f8eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2272/2272 [==============================] - 74s 28ms/step - loss: 0.3877 - accuracy: 0.8216 - val_loss: 0.3497 - val_accuracy: 0.8447\n",
      "Epoch 2/5\n",
      "2272/2272 [==============================] - 49s 21ms/step - loss: 0.2796 - accuracy: 0.8850 - val_loss: 0.3418 - val_accuracy: 0.8491\n",
      "Epoch 3/5\n",
      "2272/2272 [==============================] - 38s 17ms/step - loss: 0.2172 - accuracy: 0.9131 - val_loss: 0.3606 - val_accuracy: 0.8484\n",
      "Epoch 4/5\n",
      "2272/2272 [==============================] - 52s 23ms/step - loss: 0.1700 - accuracy: 0.9326 - val_loss: 0.3922 - val_accuracy: 0.8485\n",
      "Epoch 5/5\n",
      "2272/2272 [==============================] - 53s 23ms/step - loss: 0.1355 - accuracy: 0.9473 - val_loss: 0.4276 - val_accuracy: 0.8428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa80dc4aca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# 같은 모델 구조로 학습\n",
    "konlpy_model = Sequential([\n",
    "    Embedding(input_dim=len(konlpy_tokenizer.word_index) + 1, output_dim=128, mask_zero=True),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "konlpy_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 레이블 데이터 준비\n",
    "train_labels = filtered_train_data['label'].values\n",
    "test_labels = filtered_test_data['label'].values\n",
    "\n",
    "# 모델 학습\n",
    "konlpy_model.fit(train_tensor_konlpy, train_labels, \n",
    "                 validation_data=(test_tensor_konlpy, test_labels),\n",
    "                 epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db96cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 22s 15ms/step - loss: 0.4276 - accuracy: 0.8428\n",
      "KoNLPy 기반 테스트 정확도: 0.8428\n"
     ]
    }
   ],
   "source": [
    "konlpy_test_loss, konlpy_test_acc = konlpy_model.evaluate(test_tensor_konlpy, test_labels)\n",
    "print(f\"KoNLPy 기반 테스트 정확도: {konlpy_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71bfff5",
   "metadata": {},
   "source": [
    "#### SentencePiece VS Komoran\n",
    "테스트 정확도   \n",
    "0.8527 > 0.8428"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
